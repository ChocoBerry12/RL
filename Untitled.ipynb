{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "import gym\n",
    "import random\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "ALPHA = .001\n",
    "EPSILON = 1\n",
    "T = 20 # T step 만큼 데이터 쌓고 학습할 것\n",
    "LAMBDA = .95\n",
    "K = 3\n",
    "GAMMA = .99\n",
    "e = .05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PPO, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 256)\n",
    "        self.fc_pi = nn.Linear(256, 2)\n",
    "        self.fc_v = nn.Linear(256,1)\n",
    "        self.optimizer = optim.Adam(self.parameters(), ALPHA)\n",
    "    \n",
    "    def pi(self, x, softmax_dim=0):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        prob = torch.softmax(self.fc_pi(x), dim = softmax_dim) # batch 처리 (학습할 떈 1 차원)\n",
    "        return prob\n",
    "    \n",
    "    def v(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc_v(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net, data, optimizer):\n",
    "    s, a, r, s2, d, prob = batch_factory(data)\n",
    "\n",
    "    # epoch K 만큼\n",
    "    for i in range(K):\n",
    "        td_target = r + GAMMA * net.v(s2)\n",
    "        delta = td_target - net.v(s)\n",
    "        delta = delta.detach().numpy() # 1 step advantage\n",
    "        advantage_lst = []\n",
    "        advantage = 0.0\n",
    "\n",
    "        # GAE 계산\n",
    "        for delta_t in delta[::-1]:\n",
    "            advantage = GAMMA * LAMBDA * advantage + delta_t[0]\n",
    "            advantage_lst.append([advantage])\n",
    "        advantage_lst.reverse()\n",
    "        advantage = torch.tensor(advantage_lst, dtype=torch.float)\n",
    "\n",
    "        pi = net.pi(s, softmax_dim=1)\n",
    "        pi_a = pi.gather(1, a)\n",
    "        ratio = torch.exp(torch.log(pi_a) - torch.log(prob))\n",
    "\n",
    "        surr1 = ratio * advantage\n",
    "        surr2 = torch.clamp(ratio, 1 - e, 1 + e) * advantage\n",
    "        loss = -torch.min(surr1, surr2) + F.smooth_l1_loss(net.v(s) , td_target.detach())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.mean().backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_factory(memory):\n",
    "    s_, a_, r_, s2_, d_, prob_ = [], [], [], [], [], []\n",
    "    for s, a, r, s2, d, p in memory:\n",
    "        s_.append(s)\n",
    "        a_.append([a])\n",
    "        r = -100 if d else r\n",
    "        r_.append([r])\n",
    "        s2_.append(s2)\n",
    "        d = 0 if d else 1\n",
    "        d_.append([d])\n",
    "        prob_.append([p])\n",
    "        \n",
    "    s_ = torch.tensor(s_, dtype=torch.float)\n",
    "    a_ = torch.tensor(a_)\n",
    "    r_ = torch.tensor(r_, dtype=torch.float)\n",
    "    s2_ = torch.tensor(s2_, dtype=torch.float)\n",
    "    d_ = torch.tensor(d_, dtype=torch.float)\n",
    "    prob_ = torch.tensor(prob_)\n",
    "    \n",
    "    return s_, a_, r_, s2_, d_, prob_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 20.6\n",
      "20 24.8\n",
      "30 39.5\n",
      "40 21.8\n",
      "50 40.9\n",
      "60 43.5\n",
      "70 53.0\n",
      "80 64.7\n",
      "90 72.3\n",
      "100 76.2\n",
      "110 86.3\n",
      "120 127.8\n",
      "130 66.1\n",
      "140 85.6\n",
      "150 128.2\n",
      "160 219.4\n",
      "170 147.1\n",
      "180 231.1\n",
      "190 248.9\n",
      "200 187.8\n",
      "210 534.2\n",
      "220 397.8\n",
      "230 173.2\n",
      "240 223.2\n",
      "250 305.4\n",
      "260 147.8\n",
      "270 212.4\n",
      "280 92.2\n",
      "290 143.3\n",
      "300 204.0\n",
      "310 171.8\n",
      "320 48.8\n",
      "330 24.0\n",
      "340 23.0\n",
      "350 25.8\n",
      "360 123.2\n",
      "370 132.0\n",
      "380 185.9\n",
      "390 122.1\n",
      "400 174.8\n",
      "410 186.7\n",
      "420 137.8\n",
      "430 112.5\n",
      "440 230.0\n",
      "450 420.6\n",
      "460 269.9\n",
      "470 195.0\n",
      "480 596.1\n",
      "490 1374.5\n",
      "500 497.0\n",
      "510 523.8\n",
      "520 1053.8\n",
      "530 108.9\n",
      "540 212.4\n",
      "550 1097.7\n",
      "560 538.2\n",
      "570 874.5\n",
      "580 1787.5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-153-8b7fd3790e0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mtrain_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-151-d6f19df91dac>\u001b[0m in \u001b[0;36mtrain_net\u001b[1;34m(net, data, optimizer)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     99\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_exp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = PPO()\n",
    "ep = 1\n",
    "total_ep = 10000\n",
    "gamma = .95\n",
    "total_reward = 0\n",
    "data = []\n",
    "optimizer = optim.Adam(net.parameters(), ALPHA)\n",
    "\n",
    "while(ep < total_ep):\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    while(not done):\n",
    "        # T step 움직인 후 clipping - T 가 너무 크면 불안정??\n",
    "        for t in range(T):\n",
    "            prob = net.pi(torch.from_numpy(state).float())\n",
    "            action = Categorical(prob).sample().item()\n",
    "            state_next, reward, done, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            data.append((state, action, reward/100.0, state_next, done, prob[action].item()))\n",
    "            state = state_next\n",
    "            if(done):\n",
    "                break\n",
    "\n",
    "        train_net(net, data, optimizer)\n",
    "        data = []\n",
    "        \n",
    "    ep += 1\n",
    "    if(ep%10 == 0):\n",
    "        print(ep, total_reward/10.0)\n",
    "        total_reward = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
