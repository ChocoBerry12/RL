{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acrobot\n",
    "---\n",
    ">단순한 환경이지만 cartpole 과 많이 다르다. 우선 오랫동안 버티는 환경과 달리 terminal state 로 빠르게 가는 것이 목적이다. 동시에 제한시간도 있다. 시간제한을 넘기면 아예 가치가 없는 episode 가 되어버린다. 이런 경험은 그냥 버려야한다. 그래서 최대한 많은 랜덤시도를 해야한다. 당연히 시간이 오래걸린다. 실패가 아닌 성공으로부터 학습을 하므로 우선 성공을 하는것이 중요하다. 또한 이러한 이유때문에 episodic 하게 학습을 해야한다.\n",
    "\n",
    "\n",
    "* state : 조인트 2 개의 sin, cos, 각속도 - continuous\n",
    "* action : 조인트 사이에 힘을 +1, 0, -1\n",
    "* reward : 매 프레임마다 -1, 500 프레임이 넘어가면 자연스럽게 종료\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook  \n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Acrobot-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_in = env.observation_space.shape[0]\n",
    "size_out = env.action_space.n\n",
    "size_w1 = 8\n",
    "size_w2 = 12\n",
    "size_w3 = 6\n",
    "\n",
    "lr = .1\n",
    "total_episode = 1000\n",
    "epsilon = 1\n",
    "gamma = .95\n",
    "\n",
    "reward = tf.placeholder(tf.float32)\n",
    "STATE_IN = tf.placeholder(tf.float32, [None, size_in])\n",
    "W_1 = tf.Variable(tf.random_normal([size_in, size_w1],stddev=.01), name='W_1')\n",
    "W_2 = tf.Variable(tf.random_normal([size_w1, size_w2],stddev=.01), name='W_2')\n",
    "W_3 = tf.Variable(tf.random_normal([size_w2, size_w3],stddev=.01), name='W_3')\n",
    "out = tf.Variable(tf.random_normal([size_w3, size_out],stddev=.01), name='W_out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_1 = tf.matmul(STATE_IN, W_1)\n",
    "L_2 = tf.matmul(L_1, W_2)\n",
    "L_3 = tf.matmul(L_2, W_3)\n",
    "L_out = tf.tanh(tf.matmul(L_3, out)) ##활성화함수가 tanh - \n",
    "\n",
    "# simple policy gradient 학습 - likelihood x Q\n",
    "loss = tf.reduce_mean(tf.log(L_out)*reward)\n",
    "train = tf.train.AdamOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discounted_reward(r):\n",
    "    dr = np.zeros_like(r)\n",
    "    sum_r = 0\n",
    "    \n",
    "    for i in reversed(range(0, r.size)):\n",
    "        sum_r = gamma*sum_r + r[i]\n",
    "        dr[i] = sum_r  \n",
    "    \n",
    "    return dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -438.0 0.99\n",
      "2 -464.0 0.9801\n",
      "3 -296.0 0.9702989999999999\n",
      "4 -306.0 0.96059601\n",
      "5 -336.0 0.9509900498999999\n",
      "6 -401.0 0.9414801494009999\n",
      "7 -408.0 0.9320653479069899\n",
      "8 -491.0 0.92274469442792\n",
      "9 -475.0 0.9135172474836407\n",
      "------------ 1.0 평균 : -409.5 ------\n",
      "10 -480.0 0.9043820750088043\n",
      "11 -285.0 0.8953382542587163\n",
      "12 -468.0 0.8863848717161291\n",
      "13 -439.0 0.8775210229989678\n",
      "14 -466.0 0.8687458127689781\n",
      "15 -376.0 0.8600583546412883\n",
      "16 -363.0 0.8514577710948754\n",
      "17 -337.0 0.8429431933839266\n",
      "18 -297.0 0.8345137614500874\n",
      "19 -396.0 0.8261686238355865\n",
      "------------ 2.0 평균 : -365.0 ------\n",
      "20 -223.0 0.8179069375972307\n",
      "21 -468.0 0.8097278682212583\n",
      "22 -314.0 0.8016305895390458\n",
      "23 -210.0 0.7936142836436553\n",
      "24 -410.0 0.7856781408072188\n",
      "25 -310.0 0.7778213593991465\n",
      "26 -246.0 0.7700431458051551\n",
      "27 -256.0 0.7623427143471035\n",
      "28 -239.0 0.7547192872036325\n",
      "29 -350.0 0.7471720943315961\n",
      "------------ 3.0 평균 : -305.1 ------\n",
      "30 -248.0 0.7397003733882802\n",
      "31 -228.0 0.7323033696543974\n",
      "32 -365.0 0.7249803359578534\n",
      "33 -219.0 0.7177305325982748\n",
      "34 -283.0 0.7105532272722921\n",
      "35 -334.0 0.7034476949995692\n",
      "36 -243.0 0.6964132180495735\n",
      "37 -229.0 0.6894490858690777\n",
      "38 -167.0 0.682554595010387\n",
      "39 -250.0 0.6757290490602831\n",
      "------------ 4.0 평균 : -252.1 ------\n",
      "40 -203.0 0.6689717585696803\n",
      "41 -274.0 0.6622820409839835\n",
      "42 -253.0 0.6556592205741436\n",
      "43 -208.0 0.6491026283684022\n",
      "44 -251.0 0.6426116020847181\n",
      "45 -323.0 0.6361854860638709\n",
      "46 -146.0 0.6298236312032323\n",
      "47 -299.0 0.6235253948912\n",
      "48 -191.0 0.617290140942288\n",
      "49 -242.0 0.6111172395328651\n",
      "------------ 5.0 평균 : -242.3 ------\n",
      "50 -236.0 0.6050060671375365\n",
      "51 -291.0 0.5989560064661611\n",
      "52 -224.0 0.5929664464014994\n",
      "53 -202.0 0.5870367819374844\n",
      "54 -243.0 0.5811664141181095\n",
      "55 -318.0 0.5753547499769285\n",
      "56 -177.0 0.5696012024771592\n",
      "57 -202.0 0.5639051904523876\n",
      "58 -244.0 0.5582661385478638\n",
      "59 -301.0 0.5526834771623851\n",
      "------------ 6.0 평균 : -232.8 ------\n",
      "60 -126.0 0.5471566423907612\n",
      "61 -190.0 0.5416850759668536\n",
      "62 -195.0 0.536268225207185\n",
      "63 -225.0 0.5309055429551132\n",
      "64 -322.0 0.525596487525562\n",
      "65 -206.0 0.5203405226503064\n",
      "66 -240.0 0.5151371174238033\n",
      "67 -153.0 0.5099857462495653\n",
      "68 -300.0 0.5048858887870696\n",
      "69 -205.0 0.4998370298991989\n",
      "------------ 7.0 평균 : -225.6 ------\n",
      "70 -220.0 0.49483865960020695\n",
      "71 -141.0 0.4898902730042049\n",
      "72 -146.0 0.48499137027416284\n",
      "73 -186.0 0.4801414565714212\n",
      "74 -208.0 0.475340042005707\n",
      "75 -140.0 0.47058664158564995\n",
      "76 -173.0 0.4658807751697934\n",
      "77 -198.0 0.4612219674180955\n",
      "78 -242.0 0.45660974774391455\n",
      "79 -161.0 0.4520436502664754\n",
      "------------ 8.0 평균 : -174.0 ------\n",
      "80 -145.0 0.44752321376381066\n",
      "81 -94.0 0.44304798162617254\n",
      "82 -187.0 0.4386175018099108\n",
      "83 -191.0 0.4342313267918117\n",
      "84 -158.0 0.4298890135238936\n",
      "85 -190.0 0.42559012338865465\n",
      "86 -186.0 0.4213342221547681\n",
      "87 -172.0 0.41712087993322045\n",
      "88 -166.0 0.41294967113388825\n",
      "89 -183.0 0.40882017442254937\n",
      "------------ 9.0 평균 : -173.0 ------\n",
      "90 -203.0 0.4047319726783239\n",
      "91 -173.0 0.40068465295154065\n",
      "92 -237.0 0.39667780642202527\n",
      "93 -198.0 0.392711028357805\n",
      "94 -135.0 0.38878391807422696\n",
      "95 -178.0 0.3848960788934847\n",
      "96 -122.0 0.38104711810454983\n",
      "97 -282.0 0.37723664692350434\n",
      "98 -158.0 0.37346428045426927\n",
      "99 -149.0 0.36972963764972655\n",
      "------------ 10.0 평균 : -193.9 ------\n",
      "100 -307.0 0.36603234127322926\n",
      "101 -166.0 0.36237201786049694\n",
      "102 -201.0 0.358748297681892\n",
      "103 -115.0 0.35516081470507305\n",
      "104 -167.0 0.3516092065580223\n",
      "105 -112.0 0.34809311449244207\n",
      "106 -154.0 0.34461218334751764\n",
      "107 -132.0 0.34116606151404244\n",
      "108 -253.0 0.337754400898902\n",
      "109 -208.0 0.334376856889913\n",
      "------------ 11.0 평균 : -173.2 ------\n",
      "110 -224.0 0.33103308832101386\n",
      "111 -131.0 0.3277227574378037\n",
      "112 -158.0 0.3244455298634257\n",
      "113 -215.0 0.3212010745647914\n",
      "114 -98.0 0.3179890638191435\n",
      "115 -111.0 0.31480917318095203\n",
      "116 -217.0 0.3116610814491425\n",
      "117 -141.0 0.30854447063465107\n",
      "118 -145.0 0.30545902592830454\n",
      "119 -108.0 0.3024044356690215\n",
      "------------ 12.0 평균 : -142.7 ------\n",
      "120 -103.0 0.29938039131233124\n",
      "121 -157.0 0.2963865873992079\n",
      "122 -226.0 0.29342272152521587\n",
      "123 -136.0 0.2904884943099637\n",
      "124 -122.0 0.28758360936686406\n",
      "125 -170.0 0.2847077732731954\n",
      "126 -115.0 0.28186069554046345\n",
      "127 -194.0 0.2790420885850588\n",
      "128 -153.0 0.2762516676992082\n",
      "129 -169.0 0.27348915102221616\n",
      "------------ 13.0 평균 : -157.7 ------\n",
      "130 -135.0 0.270754259511994\n",
      "131 -193.0 0.26804671691687404\n",
      "132 -142.0 0.2653662497477053\n",
      "133 -250.0 0.2627125872502282\n",
      "134 -132.0 0.2600854613777259\n",
      "135 -155.0 0.2574846067639487\n",
      "136 -153.0 0.2549097606963092\n",
      "137 -93.0 0.2523606630893461\n",
      "138 -139.0 0.24983705645845267\n",
      "139 -118.0 0.24733868589386815\n",
      "------------ 14.0 평균 : -146.9 ------\n",
      "140 -94.0 0.24486529903492946\n",
      "141 -153.0 0.24241664604458016\n",
      "142 -128.0 0.23999247958413436\n",
      "143 -95.0 0.23759255478829303\n",
      "144 -161.0 0.2352166292404101\n",
      "145 -182.0 0.232864462948006\n",
      "146 -129.0 0.23053581831852593\n",
      "147 -199.0 0.22823046013534068\n",
      "148 -148.0 0.22594815553398728\n",
      "149 -130.0 0.22368867397864742\n",
      "------------ 15.0 평균 : -143.5 ------\n",
      "150 -110.0 0.22145178723886094\n",
      "151 -131.0 0.21923726936647234\n",
      "152 -97.0 0.2170448966728076\n",
      "153 -145.0 0.21487444770607952\n",
      "154 -128.0 0.21272570322901874\n",
      "155 -118.0 0.21059844619672854\n",
      "156 -167.0 0.20849246173476127\n",
      "157 -88.0 0.20640753711741366\n",
      "158 -171.0 0.20434346174623952\n",
      "159 -177.0 0.20230002712877712\n",
      "------------ 16.0 평균 : -137.9 ------\n",
      "160 -157.0 0.20027702685748935\n",
      "161 -113.0 0.19827425658891445\n",
      "162 -157.0 0.2\n",
      "163 -101.0 0.198\n",
      "164 -119.0 0.2\n",
      "165 -118.0 0.198\n",
      "166 -82.0 0.2\n",
      "167 -154.0 0.198\n",
      "168 -129.0 0.2\n",
      "169 -91.0 0.198\n",
      "------------ 17.0 평균 : -117.2 ------\n",
      "170 -108.0 0.2\n",
      "171 -189.0 0.198\n",
      "172 -150.0 0.2\n",
      "173 -102.0 0.198\n",
      "174 -81.0 0.2\n",
      "175 -175.0 0.198\n",
      "176 -130.0 0.2\n",
      "177 -126.0 0.198\n",
      "178 -144.0 0.2\n",
      "179 -114.0 0.198\n",
      "------------ 18.0 평균 : -131.9 ------\n",
      "180 -108.0 0.2\n",
      "181 -107.0 0.198\n",
      "182 -113.0 0.2\n",
      "183 -147.0 0.198\n",
      "184 -99.0 0.2\n",
      "185 -152.0 0.198\n",
      "186 -108.0 0.2\n",
      "187 -153.0 0.198\n",
      "188 -172.0 0.2\n",
      "189 -182.0 0.198\n",
      "------------ 19.0 평균 : -135.1 ------\n",
      "190 -118.0 0.2\n",
      "191 -140.0 0.198\n",
      "192 -111.0 0.2\n",
      "193 -137.0 0.198\n",
      "194 -155.0 0.2\n",
      "195 -122.0 0.198\n",
      "196 -113.0 0.2\n",
      "197 -134.0 0.198\n",
      "198 -130.0 0.2\n",
      "199 -131.0 0.198\n",
      "------------ 20.0 평균 : -125.9 ------\n",
      "200 -86.0 0.2\n",
      "201 -131.0 0.198\n",
      "202 -110.0 0.2\n",
      "203 -101.0 0.198\n",
      "204 -222.0 0.2\n",
      "205 -124.0 0.198\n",
      "206 -165.0 0.2\n",
      "207 -115.0 0.198\n",
      "208 -105.0 0.2\n",
      "209 -245.0 0.198\n",
      "------------ 21.0 평균 : -141.6 ------\n",
      "210 -98.0 0.2\n",
      "211 -119.0 0.198\n",
      "212 -149.0 0.2\n",
      "213 -144.0 0.198\n",
      "214 -318.0 0.2\n",
      "215 -82.0 0.198\n",
      "216 -148.0 0.2\n",
      "217 -164.0 0.198\n",
      "218 -102.0 0.2\n",
      "219 -119.0 0.198\n",
      "------------ 22.0 평균 : -150.5 ------\n",
      "220 -160.0 0.2\n",
      "221 -211.0 0.198\n",
      "222 -235.0 0.2\n",
      "223 -214.0 0.198\n",
      "224 -241.0 0.2\n",
      "225 -167.0 0.198\n",
      "226 -177.0 0.2\n",
      "227 -123.0 0.198\n",
      "228 -167.0 0.2\n",
      "229 -257.0 0.198\n",
      "------------ 23.0 평균 : -195.0 ------\n",
      "230 -158.0 0.2\n",
      "231 -116.0 0.198\n",
      "232 -147.0 0.2\n",
      "233 -199.0 0.198\n",
      "234 -132.0 0.2\n",
      "235 -248.0 0.198\n",
      "236 -267.0 0.2\n",
      "237 -321.0 0.198\n",
      "238 -245.0 0.2\n",
      "239 -189.0 0.198\n",
      "------------ 24.0 평균 : -205.9 ------\n",
      "240 -195.0 0.2\n",
      "241 -175.0 0.198\n",
      "242 -134.0 0.2\n",
      "243 -251.0 0.198\n",
      "244 -184.0 0.2\n",
      "245 -173.0 0.198\n",
      "246 -157.0 0.2\n",
      "247 -173.0 0.198\n",
      "248 -176.0 0.2\n",
      "249 -254.0 0.198\n",
      "------------ 25.0 평균 : -183.7 ------\n",
      "250 -160.0 0.2\n",
      "251 -267.0 0.198\n",
      "252 -106.0 0.2\n",
      "253 -181.0 0.198\n",
      "254 -137.0 0.2\n",
      "255 -134.0 0.198\n",
      "256 -126.0 0.2\n",
      "257 -235.0 0.198\n",
      "258 -173.0 0.2\n",
      "259 -199.0 0.198\n",
      "------------ 26.0 평균 : -171.8 ------\n",
      "260 -160.0 0.2\n",
      "261 -313.0 0.198\n",
      "262 -271.0 0.2\n",
      "263 -114.0 0.198\n",
      "264 -113.0 0.2\n",
      "265 -239.0 0.198\n",
      "266 -152.0 0.2\n",
      "267 -152.0 0.198\n",
      "268 -327.0 0.2\n",
      "269 -193.0 0.198\n",
      "------------ 27.0 평균 : -202.0 ------\n",
      "270 -146.0 0.2\n",
      "271 -240.0 0.198\n",
      "272 -80.0 0.2\n",
      "273 -121.0 0.198\n",
      "274 -230.0 0.2\n",
      "275 -137.0 0.198\n",
      "276 -267.0 0.2\n",
      "277 -238.0 0.198\n",
      "278 -209.0 0.2\n",
      "279 -220.0 0.198\n",
      "------------ 28.0 평균 : -193.2 ------\n",
      "280 -190.0 0.2\n",
      "281 -124.0 0.198\n",
      "282 -153.0 0.2\n",
      "283 -249.0 0.198\n",
      "284 -344.0 0.2\n",
      "285 -359.0 0.198\n",
      "286 -158.0 0.2\n",
      "287 -368.0 0.198\n",
      "288 -200.0 0.2\n",
      "289 -263.0 0.198\n",
      "------------ 29.0 평균 : -233.9 ------\n",
      "290 -121.0 0.2\n",
      "291 -232.0 0.198\n",
      "292 -180.0 0.2\n",
      "293 -208.0 0.198\n",
      "294 -119.0 0.2\n",
      "295 -242.0 0.198\n",
      "296 -256.0 0.2\n",
      "297 -224.0 0.198\n",
      "298 -157.0 0.2\n",
      "299 -192.0 0.198\n",
      "------------ 30.0 평균 : -205.5 ------\n",
      "300 -245.0 0.2\n",
      "301 -117.0 0.198\n",
      "302 -122.0 0.2\n",
      "303 -183.0 0.198\n",
      "304 -263.0 0.2\n",
      "305 -277.0 0.198\n",
      "306 -140.0 0.2\n",
      "307 -168.0 0.198\n",
      "308 -349.0 0.2\n",
      "309 -196.0 0.198\n",
      "------------ 31.0 평균 : -207.7 ------\n",
      "310 -262.0 0.2\n",
      "311 -183.0 0.198\n",
      "312 -252.0 0.2\n",
      "313 -190.0 0.198\n",
      "314 -137.0 0.2\n",
      "315 -138.0 0.198\n",
      "316 -181.0 0.2\n",
      "317 -162.0 0.198\n",
      "318 -193.0 0.2\n",
      "319 -434.0 0.198\n",
      "------------ 32.0 평균 : -199.0 ------\n",
      "320 -120.0 0.2\n",
      "321 -329.0 0.198\n",
      "322 -216.0 0.2\n",
      "323 -381.0 0.198\n",
      "324 -196.0 0.2\n",
      "325 -342.0 0.198\n",
      "326 -174.0 0.2\n",
      "327 -189.0 0.198\n",
      "328 -120.0 0.2\n",
      "329 -382.0 0.198\n",
      "------------ 33.0 평균 : -253.3 ------\n",
      "330 -204.0 0.2\n",
      "331 -237.0 0.198\n",
      "332 -278.0 0.2\n",
      "333 -379.0 0.198\n",
      "334 -209.0 0.2\n",
      "335 -92.0 0.198\n",
      "336 -124.0 0.2\n",
      "337 -258.0 0.198\n",
      "338 -190.0 0.2\n",
      "339 -277.0 0.198\n",
      "------------ 34.0 평균 : -219.7 ------\n",
      "340 -153.0 0.2\n",
      "341 -159.0 0.198\n",
      "342 -301.0 0.2\n",
      "343 -172.0 0.198\n",
      "344 -120.0 0.2\n",
      "345 -258.0 0.198\n",
      "346 -377.0 0.2\n",
      "347 -171.0 0.198\n",
      "348 -216.0 0.2\n",
      "349 -256.0 0.198\n",
      "------------ 35.0 평균 : -218.3 ------\n",
      "350 -153.0 0.2\n",
      "351 -206.0 0.198\n",
      "352 -155.0 0.2\n",
      "353 -389.0 0.198\n",
      "354 -254.0 0.2\n",
      "355 -327.0 0.198\n",
      "356 -160.0 0.2\n",
      "357 -158.0 0.198\n",
      "358 -297.0 0.2\n",
      "359 -202.0 0.198\n",
      "------------ 36.0 평균 : -229.7 ------\n",
      "360 -149.0 0.2\n",
      "361 -141.0 0.198\n",
      "362 -114.0 0.2\n",
      "363 -143.0 0.198\n",
      "364 -160.0 0.2\n",
      "365 -118.0 0.198\n",
      "366 -132.0 0.2\n",
      "367 -83.0 0.198\n",
      "368 -96.0 0.2\n",
      "369 -93.0 0.198\n",
      "------------ 37.0 평균 : -119.7 ------\n",
      "370 -117.0 0.2\n",
      "371 -124.0 0.198\n",
      "372 -109.0 0.2\n",
      "373 -133.0 0.198\n",
      "374 -131.0 0.2\n",
      "375 -202.0 0.198\n",
      "376 -147.0 0.2\n",
      "377 -129.0 0.198\n",
      "378 -83.0 0.2\n",
      "379 -93.0 0.198\n",
      "------------ 38.0 평균 : -122.6 ------\n",
      "380 -75.0 0.2\n",
      "381 -123.0 0.198\n",
      "382 -92.0 0.2\n",
      "383 -111.0 0.198\n",
      "384 -100.0 0.2\n",
      "385 -101.0 0.198\n",
      "386 -90.0 0.2\n",
      "387 -92.0 0.198\n",
      "388 -119.0 0.2\n",
      "389 -85.0 0.198\n",
      "------------ 39.0 평균 : -113.5 ------\n",
      "390 -222.0 0.2\n",
      "391 -102.0 0.198\n",
      "392 -100.0 0.2\n",
      "393 -100.0 0.198\n",
      "394 -102.0 0.2\n",
      "395 -93.0 0.198\n",
      "396 -116.0 0.2\n",
      "397 -75.0 0.198\n",
      "398 -138.0 0.2\n",
      "399 -98.0 0.198\n",
      "------------ 40.0 평균 : -101.3 ------\n",
      "400 -89.0 0.2\n",
      "401 -116.0 0.198\n",
      "402 -110.0 0.2\n",
      "403 -121.0 0.198\n",
      "404 -83.0 0.2\n",
      "405 -103.0 0.198\n",
      "406 -126.0 0.2\n",
      "407 -116.0 0.198\n",
      "408 -115.0 0.2\n",
      "409 -190.0 0.198\n",
      "------------ 41.0 평균 : -117.9 ------\n",
      "410 -99.0 0.2\n",
      "411 -83.0 0.198\n",
      "412 -92.0 0.2\n",
      "413 -100.0 0.198\n",
      "414 -86.0 0.2\n",
      "415 -90.0 0.198\n",
      "416 -100.0 0.2\n",
      "417 -114.0 0.198\n",
      "418 -152.0 0.2\n",
      "419 -87.0 0.198\n",
      "------------ 42.0 평균 : -100.6 ------\n",
      "420 -102.0 0.2\n",
      "421 -117.0 0.198\n",
      "422 -103.0 0.2\n",
      "423 -98.0 0.198\n",
      "424 -99.0 0.2\n",
      "425 -95.0 0.198\n",
      "426 -120.0 0.2\n",
      "427 -88.0 0.198\n",
      "428 -92.0 0.2\n",
      "429 -98.0 0.198\n",
      "------------ 43.0 평균 : -100.9 ------\n",
      "430 -99.0 0.2\n",
      "431 -127.0 0.198\n",
      "432 -93.0 0.2\n",
      "433 -162.0 0.198\n",
      "434 -90.0 0.2\n",
      "435 -76.0 0.198\n",
      "436 -89.0 0.2\n",
      "437 -82.0 0.198\n",
      "438 -100.0 0.2\n",
      "439 -105.0 0.198\n",
      "------------ 44.0 평균 : -102.5 ------\n",
      "440 -101.0 0.2\n",
      "441 -85.0 0.198\n",
      "442 -95.0 0.2\n",
      "443 -79.0 0.198\n",
      "444 -104.0 0.2\n",
      "445 -139.0 0.198\n",
      "446 -71.0 0.2\n",
      "447 -101.0 0.198\n",
      "448 -70.0 0.2\n",
      "449 -87.0 0.198\n",
      "------------ 45.0 평균 : -89.3 ------\n",
      "450 -62.0 0.2\n",
      "451 -108.0 0.198\n",
      "452 -92.0 0.2\n",
      "453 -100.0 0.198\n",
      "454 -103.0 0.2\n",
      "455 -111.0 0.198\n",
      "456 -83.0 0.2\n",
      "457 -82.0 0.198\n",
      "458 -90.0 0.2\n",
      "459 -94.0 0.198\n",
      "------------ 46.0 평균 : -94.7 ------\n",
      "460 -84.0 0.2\n",
      "461 -87.0 0.198\n",
      "462 -77.0 0.2\n",
      "463 -112.0 0.198\n",
      "464 -80.0 0.2\n",
      "465 -109.0 0.198\n",
      "466 -115.0 0.2\n",
      "467 -85.0 0.198\n",
      "468 -115.0 0.2\n",
      "469 -96.0 0.198\n",
      "------------ 47.0 평균 : -99.6 ------\n",
      "470 -120.0 0.2\n",
      "471 -89.0 0.198\n",
      "472 -107.0 0.2\n",
      "473 -95.0 0.198\n",
      "474 -91.0 0.2\n",
      "475 -89.0 0.198\n",
      "476 -86.0 0.2\n",
      "477 -97.0 0.198\n",
      "478 -92.0 0.2\n",
      "479 -100.0 0.198\n",
      "------------ 48.0 평균 : -95.2 ------\n",
      "480 -106.0 0.2\n",
      "481 -143.0 0.198\n",
      "482 -106.0 0.2\n",
      "483 -83.0 0.198\n",
      "484 -269.0 0.2\n",
      "485 -109.0 0.198\n",
      "486 -91.0 0.2\n",
      "487 -94.0 0.198\n",
      "488 -94.0 0.2\n",
      "489 -93.0 0.198\n",
      "------------ 49.0 평균 : -116.2 ------\n",
      "490 -80.0 0.2\n",
      "491 -94.0 0.198\n",
      "492 -92.0 0.2\n",
      "493 -80.0 0.198\n",
      "494 -123.0 0.2\n",
      "495 -82.0 0.198\n",
      "496 -91.0 0.2\n",
      "497 -99.0 0.198\n",
      "498 -77.0 0.2\n",
      "499 -86.0 0.198\n",
      "------------ 50.0 평균 : -91.5 ------\n",
      "500 -91.0 0.2\n",
      "501 -89.0 0.198\n",
      "502 -108.0 0.2\n",
      "503 -91.0 0.198\n",
      "504 -498.0 0.2\n",
      "505 -147.0 0.198\n",
      "506 -85.0 0.2\n",
      "507 -115.0 0.198\n",
      "508 -93.0 0.2\n",
      "509 -113.0 0.198\n",
      "------------ 51.0 평균 : -144.7 ------\n",
      "510 -108.0 0.2\n",
      "511 -83.0 0.198\n",
      "512 -115.0 0.2\n",
      "513 -116.0 0.198\n",
      "514 -116.0 0.2\n",
      "515 -75.0 0.198\n",
      "516 -136.0 0.2\n",
      "517 -89.0 0.198\n",
      "518 -78.0 0.2\n",
      "519 -98.0 0.198\n",
      "------------ 52.0 평균 : -100.6 ------\n",
      "520 -100.0 0.2\n",
      "521 -108.0 0.198\n",
      "522 -105.0 0.2\n",
      "523 -95.0 0.198\n",
      "524 -90.0 0.2\n",
      "525 -92.0 0.198\n",
      "526 -97.0 0.2\n",
      "527 -86.0 0.198\n",
      "528 -107.0 0.2\n",
      "529 -92.0 0.198\n",
      "------------ 53.0 평균 : -96.1 ------\n",
      "530 -89.0 0.2\n",
      "531 -193.0 0.198\n",
      "532 -114.0 0.2\n",
      "533 -88.0 0.198\n",
      "534 -90.0 0.2\n",
      "535 -88.0 0.198\n",
      "536 -104.0 0.2\n",
      "537 -175.0 0.198\n",
      "538 -97.0 0.2\n",
      "539 -108.0 0.198\n",
      "------------ 54.0 평균 : -116.8 ------\n",
      "540 -111.0 0.2\n",
      "541 -83.0 0.198\n",
      "542 -97.0 0.2\n",
      "543 -100.0 0.198\n",
      "544 -116.0 0.2\n",
      "545 -114.0 0.198\n",
      "546 -99.0 0.2\n",
      "547 -126.0 0.198\n",
      "548 -93.0 0.2\n",
      "549 -87.0 0.198\n",
      "------------ 55.0 평균 : -102.9 ------\n",
      "550 -114.0 0.2\n",
      "551 -153.0 0.198\n",
      "552 -95.0 0.2\n",
      "553 -83.0 0.198\n",
      "554 -191.0 0.2\n",
      "555 -82.0 0.198\n",
      "556 -133.0 0.2\n",
      "557 -132.0 0.198\n",
      "558 -79.0 0.2\n",
      "559 -88.0 0.198\n",
      "------------ 56.0 평균 : -112.7 ------\n",
      "560 -91.0 0.2\n",
      "561 -93.0 0.198\n",
      "562 -101.0 0.2\n",
      "563 -111.0 0.198\n",
      "564 -88.0 0.2\n",
      "565 -107.0 0.198\n",
      "566 -80.0 0.2\n",
      "567 -91.0 0.198\n",
      "568 -99.0 0.2\n",
      "569 -94.0 0.198\n",
      "------------ 57.0 평균 : -97.2 ------\n",
      "570 -108.0 0.2\n",
      "571 -109.0 0.198\n",
      "572 -195.0 0.2\n",
      "573 -119.0 0.198\n",
      "574 -93.0 0.2\n",
      "575 -101.0 0.198\n",
      "576 -85.0 0.2\n",
      "577 -103.0 0.198\n",
      "578 -82.0 0.2\n",
      "579 -112.0 0.198\n",
      "------------ 58.0 평균 : -110.7 ------\n",
      "580 -108.0 0.2\n",
      "581 -114.0 0.198\n",
      "582 -83.0 0.2\n",
      "583 -86.0 0.198\n",
      "584 -105.0 0.2\n",
      "585 -91.0 0.198\n",
      "586 -86.0 0.2\n",
      "587 -80.0 0.198\n",
      "588 -159.0 0.2\n",
      "589 -110.0 0.198\n",
      "------------ 59.0 평균 : -100.7 ------\n",
      "590 -93.0 0.2\n",
      "591 -104.0 0.198\n",
      "592 -99.0 0.2\n",
      "593 -76.0 0.198\n",
      "594 -99.0 0.2\n",
      "595 -86.0 0.198\n",
      "596 -111.0 0.2\n",
      "597 -107.0 0.198\n",
      "598 -94.0 0.2\n",
      "599 -108.0 0.198\n",
      "------------ 60.0 평균 : -96.9 ------\n",
      "600 -85.0 0.2\n",
      "601 -75.0 0.198\n",
      "602 -140.0 0.2\n",
      "603 -102.0 0.198\n",
      "604 -84.0 0.2\n",
      "605 -92.0 0.198\n",
      "606 -87.0 0.2\n",
      "607 -99.0 0.198\n",
      "608 -98.0 0.2\n",
      "609 -88.0 0.198\n",
      "------------ 61.0 평균 : -92.8 ------\n",
      "610 -63.0 0.2\n",
      "611 -117.0 0.198\n",
      "612 -95.0 0.2\n",
      "613 -97.0 0.198\n",
      "614 -139.0 0.2\n",
      "615 -114.0 0.198\n",
      "616 -146.0 0.2\n",
      "617 -127.0 0.198\n",
      "618 -107.0 0.2\n",
      "619 -149.0 0.198\n",
      "------------ 62.0 평균 : -122.1 ------\n",
      "620 -130.0 0.2\n",
      "621 -92.0 0.198\n",
      "622 -81.0 0.2\n",
      "623 -98.0 0.198\n",
      "624 -94.0 0.2\n",
      "625 -78.0 0.198\n",
      "626 -86.0 0.2\n",
      "627 -83.0 0.198\n",
      "628 -83.0 0.2\n",
      "629 -92.0 0.198\n",
      "------------ 63.0 평균 : -86.8 ------\n",
      "630 -81.0 0.2\n",
      "631 -82.0 0.198\n",
      "632 -63.0 0.2\n",
      "633 -211.0 0.198\n",
      "634 -88.0 0.2\n",
      "635 -119.0 0.198\n",
      "636 -99.0 0.2\n",
      "637 -97.0 0.198\n",
      "638 -93.0 0.2\n",
      "639 -98.0 0.198\n",
      "------------ 64.0 평균 : -103.2 ------\n",
      "640 -82.0 0.2\n",
      "641 -104.0 0.198\n",
      "642 -85.0 0.2\n",
      "643 -71.0 0.198\n",
      "644 -103.0 0.2\n",
      "645 -80.0 0.198\n",
      "646 -134.0 0.2\n",
      "647 -113.0 0.198\n",
      "648 -95.0 0.2\n",
      "649 -101.0 0.198\n",
      "------------ 65.0 평균 : -98.8 ------\n",
      "650 -102.0 0.2\n",
      "651 -217.0 0.198\n",
      "652 -123.0 0.2\n",
      "653 -94.0 0.198\n",
      "654 -95.0 0.2\n",
      "655 -141.0 0.198\n",
      "656 -90.0 0.2\n",
      "657 -115.0 0.198\n",
      "658 -107.0 0.2\n",
      "659 -80.0 0.198\n",
      "------------ 66.0 평균 : -117.4 ------\n",
      "660 -112.0 0.2\n",
      "661 -92.0 0.198\n",
      "662 -92.0 0.2\n",
      "663 -96.0 0.198\n",
      "664 -113.0 0.2\n",
      "665 -87.0 0.198\n",
      "666 -90.0 0.2\n",
      "667 -127.0 0.198\n",
      "668 -106.0 0.2\n",
      "669 -96.0 0.198\n",
      "------------ 67.0 평균 : -99.0 ------\n",
      "670 -91.0 0.2\n",
      "671 -100.0 0.198\n",
      "672 -109.0 0.2\n",
      "673 -84.0 0.198\n",
      "674 -79.0 0.2\n",
      "675 -118.0 0.198\n",
      "676 -110.0 0.2\n",
      "677 -77.0 0.198\n",
      "678 -118.0 0.2\n",
      "679 -191.0 0.198\n",
      "------------ 68.0 평균 : -105.7 ------\n",
      "680 -71.0 0.2\n",
      "681 -72.0 0.198\n",
      "682 -134.0 0.2\n",
      "683 -96.0 0.198\n",
      "684 -90.0 0.2\n",
      "685 -109.0 0.198\n",
      "686 -77.0 0.2\n",
      "687 -125.0 0.198\n",
      "688 -118.0 0.2\n",
      "689 -109.0 0.198\n",
      "------------ 69.0 평균 : -103.8 ------\n",
      "690 -108.0 0.2\n",
      "691 -76.0 0.198\n",
      "692 -90.0 0.2\n",
      "693 -86.0 0.198\n",
      "694 -89.0 0.2\n",
      "695 -107.0 0.198\n",
      "696 -78.0 0.2\n",
      "697 -108.0 0.198\n",
      "698 -97.0 0.2\n",
      "699 -92.0 0.198\n",
      "------------ 70.0 평균 : -92.5 ------\n",
      "700 -102.0 0.2\n",
      "701 -90.0 0.198\n",
      "702 -92.0 0.2\n",
      "703 -99.0 0.198\n",
      "704 -72.0 0.2\n",
      "705 -105.0 0.198\n",
      "706 -68.0 0.2\n",
      "707 -85.0 0.198\n",
      "708 -86.0 0.2\n",
      "709 -101.0 0.198\n",
      "------------ 71.0 평균 : -88.3 ------\n",
      "710 -85.0 0.2\n",
      "711 -102.0 0.198\n",
      "712 -153.0 0.2\n",
      "713 -195.0 0.198\n",
      "714 -131.0 0.2\n",
      "715 -83.0 0.198\n",
      "716 -73.0 0.2\n",
      "717 -89.0 0.198\n",
      "718 -104.0 0.2\n",
      "719 -76.0 0.198\n",
      "------------ 72.0 평균 : -108.9 ------\n",
      "720 -83.0 0.2\n",
      "721 -154.0 0.198\n",
      "722 -116.0 0.2\n",
      "723 -115.0 0.198\n",
      "724 -112.0 0.2\n",
      "725 -101.0 0.198\n",
      "726 -114.0 0.2\n",
      "727 -94.0 0.198\n",
      "728 -88.0 0.2\n",
      "729 -87.0 0.198\n",
      "------------ 73.0 평균 : -110.7 ------\n",
      "730 -126.0 0.2\n",
      "731 -165.0 0.198\n",
      "732 -128.0 0.2\n",
      "733 -100.0 0.198\n",
      "734 -101.0 0.2\n",
      "735 -124.0 0.198\n",
      "736 -123.0 0.2\n",
      "737 -119.0 0.198\n",
      "738 -110.0 0.2\n",
      "739 -118.0 0.198\n",
      "------------ 74.0 평균 : -117.4 ------\n",
      "740 -86.0 0.2\n",
      "741 -156.0 0.198\n",
      "742 -185.0 0.2\n",
      "743 -102.0 0.198\n",
      "744 -190.0 0.2\n",
      "745 -137.0 0.198\n",
      "746 -138.0 0.2\n",
      "747 -101.0 0.198\n",
      "748 -97.0 0.2\n",
      "749 -134.0 0.198\n",
      "------------ 75.0 평균 : -135.6 ------\n",
      "750 -116.0 0.2\n",
      "751 -163.0 0.198\n",
      "752 -144.0 0.2\n",
      "753 -214.0 0.198\n",
      "754 -117.0 0.2\n",
      "755 -104.0 0.198\n",
      "756 -188.0 0.2\n",
      "757 -96.0 0.198\n",
      "758 -161.0 0.2\n",
      "759 -79.0 0.198\n",
      "------------ 76.0 평균 : -139.0 ------\n",
      "760 -124.0 0.2\n",
      "761 -194.0 0.198\n",
      "762 -109.0 0.2\n",
      "763 -98.0 0.198\n",
      "764 -138.0 0.2\n",
      "765 -91.0 0.198\n",
      "766 -85.0 0.2\n",
      "767 -101.0 0.198\n",
      "768 -120.0 0.2\n",
      "769 -197.0 0.198\n",
      "------------ 77.0 평균 : -125.8 ------\n",
      "770 -125.0 0.2\n",
      "771 -124.0 0.198\n",
      "772 -126.0 0.2\n",
      "773 -181.0 0.198\n",
      "774 -101.0 0.2\n",
      "775 -133.0 0.198\n",
      "776 -114.0 0.2\n",
      "777 -95.0 0.198\n",
      "778 -115.0 0.2\n",
      "779 -97.0 0.198\n",
      "------------ 78.0 평균 : -119.5 ------\n",
      "780 -109.0 0.2\n",
      "781 -106.0 0.198\n",
      "782 -172.0 0.2\n",
      "783 -142.0 0.198\n",
      "784 -120.0 0.2\n",
      "785 -172.0 0.198\n",
      "786 -196.0 0.2\n",
      "787 -336.0 0.198\n",
      "788 -173.0 0.2\n",
      "789 -235.0 0.198\n",
      "------------ 79.0 평균 : -175.0 ------\n",
      "790 -98.0 0.2\n",
      "791 -173.0 0.198\n",
      "792 -129.0 0.2\n",
      "793 -102.0 0.198\n",
      "794 -130.0 0.2\n",
      "795 -117.0 0.198\n",
      "796 -114.0 0.2\n",
      "797 -118.0 0.198\n",
      "798 -126.0 0.2\n",
      "799 -128.0 0.198\n",
      "------------ 80.0 평균 : -135.3 ------\n",
      "800 -216.0 0.2\n",
      "801 -97.0 0.198\n",
      "802 -143.0 0.2\n",
      "803 -110.0 0.198\n",
      "804 -131.0 0.2\n",
      "805 -96.0 0.198\n",
      "806 -175.0 0.2\n",
      "807 -115.0 0.198\n",
      "808 -117.0 0.2\n",
      "809 -81.0 0.198\n",
      "------------ 81.0 평균 : -118.4 ------\n",
      "810 -119.0 0.2\n",
      "811 -128.0 0.198\n",
      "812 -127.0 0.2\n",
      "813 -115.0 0.198\n",
      "814 -331.0 0.2\n",
      "815 -274.0 0.198\n",
      "816 -262.0 0.2\n",
      "817 -117.0 0.198\n",
      "818 -210.0 0.2\n",
      "819 -206.0 0.198\n",
      "------------ 82.0 평균 : -194.4 ------\n",
      "820 -174.0 0.2\n",
      "821 -310.0 0.198\n",
      "822 -436.0 0.2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-170-b34b97d3d764>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[0mpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mSTATE_IN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m                 \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    tf.global_variables_initializer().run()\n",
    "    state_buffer = []\n",
    "    reward_buffer = []\n",
    "    ep = 0\n",
    "    state = env.reset()\n",
    "    reward_sum = 0\n",
    "    step = 0\n",
    "    is_render = False\n",
    "    mean_ep_reward = 0\n",
    "    is_trained = False\n",
    "    \n",
    "    while not is_trained:\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            \n",
    "            step = step + 1\n",
    "            state = np.reshape(state, [1, size_in])\n",
    "            state_buffer.append(state)\n",
    "\n",
    "            if(random.random() < epsilon):\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                pi = sess.run(L_out, feed_dict={STATE_IN:state})\n",
    "                action = np.argmax(pi)\n",
    "\n",
    "            new_state, r, d, _ = env.step(action)\n",
    "            state = new_state\n",
    "            reward_sum += r\n",
    "            reward_buffer.append(r)\n",
    "\n",
    "            if d:\n",
    "                if reward_sum == -500:\n",
    "                  #epsilon = 1\n",
    "                    pass\n",
    "                else:\n",
    "                    ep += 1\n",
    "                    mean_ep_reward += reward_sum\n",
    "                    \n",
    "                    if(ep % 10 == 0):\n",
    "                        mean_ep_reward = mean_ep_reward / 10\n",
    "                        print('------------ {} 평균 : {} ------'.format(ep/10,mean_ep_reward))\n",
    "                        #cartpole과는 다르게 제한시간 내로 목표에 도달하지 못하면 실패한 것으로 \n",
    "                        # 학습 종료\n",
    "                            \n",
    "                        mean_ep_reward = 0\n",
    "                        \n",
    "                    if(epsilon < .2):\n",
    "                        epsilon = .2\n",
    "                    else:\n",
    "                        epsilon *= .99\n",
    "                    \n",
    "                    '''\n",
    "                    성공의 직전 행동만 학습하는 trick\n",
    "                    '''\n",
    "                    try:\n",
    "                        state_buffer = state_buffer[len(state_buffer) - 150:]\n",
    "                        reward_buffer = reward_buffer[len(reward_buffer) - 150:]\n",
    "\n",
    "                    except:\n",
    "                        state_buffer = state_buffer[len(state_buffer) - 50:]\n",
    "                        reward_buffer = reward_buffer[len(reward_buffer) - 50:]\n",
    "                    \n",
    "                    \n",
    "                    eps = np.vstack(state_buffer)\n",
    "                    epr = np.vstack(reward_buffer)\n",
    "                    epr = discounted_reward(epr)\n",
    "                    \n",
    "                    sess.run(train, feed_dict={STATE_IN:eps, reward:epr})                    \n",
    "                    print(ep, reward_sum, epsilon)\n",
    "\n",
    "                state_buffer, reward_buffer = [],[]                \n",
    "                reward_sum = 0\n",
    "                done = True\n",
    "                state = env.reset()\n",
    "                step = 0\n",
    "\n",
    "    done = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
