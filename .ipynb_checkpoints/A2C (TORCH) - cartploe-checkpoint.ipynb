{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advantage Actor Critic\n",
    "---\n",
    "* detach 는 상수취급 해야할 때 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "import gym\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "EPSILON = 1\n",
    "ALPHA = .001\n",
    "GAMMA = .95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A2C(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(A2C, self).__init__()\n",
    "        self.fc_1 = nn.Linear(4, 128)\n",
    "        self.fc_pi = nn.Linear(128, 2)\n",
    "        self.fc_v = nn.Linear(128, 1)\n",
    "        \n",
    "    def pi(self, x):\n",
    "        x = torch.relu(self.fc_1(x))\n",
    "        x = torch.softmax(self.fc_pi(x), dim=0)\n",
    "        return x\n",
    "    \n",
    "    def v(self, x):\n",
    "        x = torch.relu(self.fc_1(x))\n",
    "        x = self.fc_v(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, data, optimizer):\n",
    "    s, a, r, s2, l_p = data\n",
    "    v_target = r + GAMMA * net.v(torch.from_numpy(s2).float())\n",
    "    advantage = v_target - net.v(torch.from_numpy(s).float())\n",
    "    \n",
    "    log_p = l_p\n",
    "    loss = F.mse_loss(v_target.detach(), net.v(torch.from_numpy(s2).float())) -log_p * advantage.detach()\n",
    "    optimizer.zero_grad()\n",
    "    loss.mean().backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.0\n",
      "19.0\n",
      "42.0\n",
      "9.0\n",
      "21.0\n",
      "15.0\n",
      "12.0\n",
      "17.0\n",
      "13.0\n",
      "16.0\n",
      "15.0\n",
      "29.0\n",
      "31.0\n",
      "38.0\n",
      "35.0\n",
      "58.0\n",
      "32.0\n",
      "16.0\n",
      "22.0\n",
      "35.0\n",
      "12.0\n",
      "10.0\n",
      "20.0\n",
      "26.0\n",
      "15.0\n",
      "36.0\n",
      "23.0\n",
      "22.0\n",
      "60.0\n",
      "30.0\n",
      "65.0\n",
      "13.0\n",
      "40.0\n",
      "13.0\n",
      "65.0\n",
      "44.0\n",
      "13.0\n",
      "15.0\n",
      "12.0\n",
      "14.0\n",
      "53.0\n",
      "18.0\n",
      "60.0\n",
      "39.0\n",
      "23.0\n",
      "24.0\n",
      "19.0\n",
      "55.0\n",
      "25.0\n",
      "28.0\n",
      "22.0\n",
      "47.0\n",
      "32.0\n",
      "40.0\n",
      "18.0\n",
      "41.0\n",
      "40.0\n",
      "39.0\n",
      "30.0\n",
      "21.0\n",
      "27.0\n",
      "42.0\n",
      "17.0\n",
      "111.0\n",
      "29.0\n",
      "65.0\n",
      "31.0\n",
      "13.0\n",
      "25.0\n",
      "77.0\n",
      "29.0\n",
      "20.0\n",
      "30.0\n",
      "101.0\n",
      "77.0\n",
      "49.0\n",
      "36.0\n",
      "44.0\n",
      "42.0\n",
      "89.0\n",
      "48.0\n",
      "41.0\n",
      "54.0\n",
      "57.0\n",
      "82.0\n",
      "74.0\n",
      "39.0\n",
      "126.0\n",
      "85.0\n",
      "56.0\n",
      "68.0\n",
      "31.0\n",
      "80.0\n",
      "72.0\n",
      "94.0\n",
      "87.0\n",
      "55.0\n",
      "93.0\n",
      "32.0\n",
      "52.0\n",
      "32.0\n",
      "26.0\n",
      "28.0\n",
      "68.0\n",
      "62.0\n",
      "102.0\n",
      "43.0\n",
      "90.0\n",
      "127.0\n",
      "129.0\n",
      "70.0\n",
      "27.0\n",
      "98.0\n",
      "81.0\n",
      "63.0\n",
      "84.0\n",
      "74.0\n",
      "66.0\n",
      "51.0\n",
      "182.0\n",
      "189.0\n",
      "107.0\n",
      "73.0\n",
      "179.0\n",
      "230.0\n",
      "409.0\n",
      "122.0\n",
      "244.0\n",
      "69.0\n",
      "128.0\n",
      "343.0\n",
      "85.0\n",
      "147.0\n",
      "97.0\n",
      "42.0\n",
      "216.0\n",
      "116.0\n",
      "124.0\n",
      "227.0\n",
      "122.0\n",
      "143.0\n",
      "53.0\n",
      "62.0\n",
      "104.0\n",
      "122.0\n",
      "222.0\n",
      "608.0\n",
      "130.0\n",
      "149.0\n",
      "230.0\n",
      "109.0\n",
      "50.0\n",
      "308.0\n",
      "244.0\n",
      "85.0\n",
      "110.0\n",
      "240.0\n",
      "76.0\n",
      "115.0\n",
      "157.0\n",
      "118.0\n",
      "233.0\n",
      "24.0\n",
      "173.0\n",
      "27.0\n",
      "125.0\n",
      "59.0\n",
      "100.0\n",
      "63.0\n",
      "226.0\n",
      "231.0\n",
      "36.0\n",
      "20.0\n",
      "34.0\n",
      "25.0\n",
      "21.0\n",
      "27.0\n",
      "26.0\n",
      "50.0\n",
      "26.0\n",
      "120.0\n",
      "107.0\n",
      "120.0\n",
      "140.0\n",
      "107.0\n",
      "117.0\n",
      "108.0\n",
      "110.0\n",
      "30.0\n",
      "116.0\n",
      "122.0\n",
      "123.0\n",
      "25.0\n",
      "41.0\n",
      "44.0\n",
      "50.0\n",
      "105.0\n",
      "114.0\n",
      "154.0\n",
      "68.0\n",
      "52.0\n",
      "104.0\n",
      "118.0\n",
      "123.0\n",
      "134.0\n",
      "67.0\n",
      "147.0\n",
      "236.0\n",
      "348.0\n",
      "106.0\n",
      "123.0\n",
      "112.0\n",
      "130.0\n",
      "127.0\n",
      "128.0\n",
      "198.0\n",
      "133.0\n",
      "120.0\n",
      "117.0\n",
      "98.0\n",
      "82.0\n",
      "105.0\n",
      "129.0\n",
      "32.0\n",
      "121.0\n",
      "99.0\n",
      "145.0\n",
      "111.0\n",
      "247.0\n",
      "58.0\n",
      "155.0\n",
      "343.0\n",
      "302.0\n",
      "514.0\n",
      "192.0\n",
      "205.0\n",
      "346.0\n",
      "82.0\n",
      "190.0\n",
      "53.0\n",
      "292.0\n",
      "249.0\n",
      "27.0\n",
      "23.0\n",
      "28.0\n",
      "22.0\n",
      "20.0\n",
      "142.0\n",
      "26.0\n",
      "16.0\n",
      "22.0\n",
      "19.0\n",
      "13.0\n",
      "15.0\n",
      "13.0\n",
      "16.0\n",
      "14.0\n",
      "14.0\n",
      "22.0\n",
      "40.0\n",
      "137.0\n",
      "167.0\n",
      "146.0\n",
      "157.0\n",
      "234.0\n",
      "232.0\n",
      "260.0\n",
      "183.0\n",
      "169.0\n",
      "120.0\n",
      "128.0\n",
      "28.0\n",
      "152.0\n",
      "17.0\n",
      "144.0\n",
      "175.0\n",
      "24.0\n",
      "137.0\n",
      "144.0\n",
      "121.0\n",
      "139.0\n",
      "154.0\n",
      "120.0\n",
      "186.0\n",
      "130.0\n",
      "115.0\n",
      "147.0\n",
      "169.0\n",
      "145.0\n",
      "155.0\n",
      "173.0\n",
      "147.0\n",
      "231.0\n",
      "251.0\n",
      "333.0\n",
      "176.0\n",
      "365.0\n",
      "305.0\n",
      "278.0\n",
      "333.0\n",
      "102.0\n",
      "18.0\n",
      "19.0\n",
      "42.0\n",
      "106.0\n",
      "104.0\n",
      "105.0\n",
      "42.0\n",
      "35.0\n",
      "116.0\n",
      "133.0\n",
      "195.0\n",
      "168.0\n",
      "397.0\n",
      "260.0\n",
      "189.0\n",
      "231.0\n",
      "141.0\n",
      "133.0\n",
      "46.0\n",
      "135.0\n",
      "115.0\n",
      "186.0\n",
      "219.0\n",
      "174.0\n",
      "226.0\n",
      "304.0\n",
      "207.0\n",
      "303.0\n",
      "227.0\n",
      "154.0\n",
      "121.0\n",
      "156.0\n",
      "155.0\n",
      "119.0\n",
      "113.0\n",
      "124.0\n",
      "151.0\n",
      "114.0\n",
      "118.0\n",
      "115.0\n",
      "101.0\n",
      "106.0\n",
      "105.0\n",
      "105.0\n",
      "104.0\n",
      "117.0\n",
      "125.0\n",
      "115.0\n",
      "137.0\n",
      "181.0\n",
      "212.0\n",
      "129.0\n",
      "220.0\n",
      "203.0\n",
      "231.0\n",
      "314.0\n",
      "178.0\n",
      "149.0\n",
      "102.0\n",
      "126.0\n",
      "118.0\n",
      "175.0\n",
      "107.0\n",
      "101.0\n",
      "91.0\n",
      "121.0\n",
      "112.0\n",
      "85.0\n",
      "113.0\n",
      "126.0\n",
      "89.0\n",
      "113.0\n",
      "114.0\n",
      "301.0\n",
      "185.0\n",
      "345.0\n",
      "341.0\n",
      "204.0\n",
      "137.0\n",
      "202.0\n",
      "126.0\n",
      "152.0\n",
      "110.0\n",
      "91.0\n",
      "65.0\n",
      "112.0\n",
      "97.0\n",
      "152.0\n",
      "112.0\n",
      "97.0\n",
      "120.0\n",
      "84.0\n",
      "181.0\n",
      "85.0\n",
      "139.0\n",
      "126.0\n",
      "180.0\n",
      "120.0\n",
      "133.0\n",
      "110.0\n",
      "203.0\n",
      "105.0\n",
      "279.0\n",
      "90.0\n",
      "265.0\n",
      "137.0\n",
      "278.0\n",
      "202.0\n",
      "156.0\n",
      "143.0\n",
      "257.0\n",
      "326.0\n",
      "137.0\n",
      "210.0\n",
      "71.0\n",
      "152.0\n",
      "260.0\n",
      "197.0\n",
      "252.0\n",
      "240.0\n",
      "2000.0\n",
      "121.0\n",
      "91.0\n",
      "74.0\n",
      "85.0\n",
      "91.0\n",
      "166.0\n",
      "146.0\n",
      "2000.0\n",
      "2000.0\n",
      "2000.0\n",
      "2000.0\n",
      "1836.0\n",
      "2000.0\n",
      "2000.0\n",
      "2000.0\n",
      "2000.0\n",
      "2000.0\n",
      "2000.0\n",
      "2000.0\n",
      "472.0\n",
      "2000.0\n",
      "2000.0\n",
      "2000.0\n",
      "2000.0\n",
      "751.0\n",
      "2000.0\n",
      "754.0\n",
      "2000.0\n",
      "2000.0\n",
      "2000.0\n",
      "541.0\n",
      "747.0\n",
      "483.0\n",
      "480.0\n",
      "20.0\n",
      "16.0\n",
      "18.0\n",
      "15.0\n",
      "315.0\n",
      "17.0\n",
      "2000.0\n",
      "29.0\n",
      "1413.0\n",
      "15.0\n",
      "14.0\n",
      "13.0\n",
      "13.0\n",
      "32.0\n",
      "13.0\n",
      "252.0\n",
      "13.0\n",
      "14.0\n",
      "13.0\n",
      "314.0\n",
      "15.0\n",
      "37.0\n",
      "356.0\n",
      "37.0\n",
      "14.0\n",
      "40.0\n",
      "17.0\n",
      "335.0\n",
      "231.0\n",
      "228.0\n",
      "266.0\n",
      "387.0\n",
      "402.0\n",
      "2000.0\n",
      "2000.0\n",
      "40.0\n",
      "42.0\n",
      "1168.0\n",
      "2000.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-fafba3a453e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mtransition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate_next\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-120-e26bda5a748a>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(net, data, optimizer)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlog_p\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0madvantage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \"\"\"\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ep = 1\n",
    "total_ep = 1000\n",
    "agent = A2C()\n",
    "optimizer = optim.Adam(agent.parameters(), ALPHA)\n",
    "\n",
    "while(ep < total_ep):\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    \n",
    "    while(not done):\n",
    "        \n",
    "        prob = agent.pi(torch.from_numpy(state).float())\n",
    "        m = Categorical(prob)\n",
    "        \n",
    "        if(random.random() < EPSILON):\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = m.sample().item()\n",
    "        \n",
    "        state_next, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        if(done):\n",
    "            reward = -100\n",
    "        log_prob = torch.log(prob[action])\n",
    "        transition = (state, action, reward, state_next, log_prob)\n",
    "        train(agent, transition, optimizer)\n",
    "\n",
    "        state = state_next\n",
    "        \n",
    "        if(done):\n",
    "            ep += 1\n",
    "            EPSILON = 1 / ((ep / 100) + 5)\n",
    "            print(total_reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
