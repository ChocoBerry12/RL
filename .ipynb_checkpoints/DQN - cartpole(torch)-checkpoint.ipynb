{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Categorical\n",
    "import gym\n",
    "import random\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "EPSILON = 1\n",
    "EPISODE = 2000\n",
    "GAMMA = .98\n",
    "ALPHA = .001\n",
    "Q_TARG_PERIOD = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN_Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 24)\n",
    "        self.fc2 = nn.Linear(24, 24)\n",
    "        self.fc3 = nn.Linear(24, 2)\n",
    "        \n",
    "    def Q(self, x):\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        #x = F.softmax(self.fc3(x), dim=0)\n",
    "        #x = F.softmax(self.fc3(x), dim=0)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(q, q_tar, optimizer):\n",
    "    \n",
    "    # buffer 에서 랜덤으로 데이터 뽑기\n",
    "    batch = random.sample(buffer, 32)\n",
    "    s_buf, a_buf, r_buf, s2_buf, d_buf = [], [], [], [], []\n",
    "    \n",
    "    # 학습리스트에 데이터 할당\n",
    "    for transition in batch:\n",
    "        s, a, r, s2, d = transition\n",
    "        s_buf.append(s)\n",
    "        a_buf.append([a])\n",
    "        r_buf.append([-100]) if d else r_buf.append([r])\n",
    "        s2_buf.append(s2)\n",
    "        d_buf.append([d])\n",
    "    \n",
    "    s_buf = torch.tensor(s_buf, dtype=torch.float)\n",
    "    a_buf = torch.tensor(a_buf)\n",
    "    r_buf = torch.tensor(r_buf)\n",
    "    s2_buf = torch.tensor(s2_buf, dtype=torch.float)\n",
    "    d_buf = torch.tensor(d_buf)\n",
    "\n",
    "    # Q 계산\n",
    "    Q = q.Q(s_buf)\n",
    "    Q = Q.gather(1, a_buf) # a_buf 를 index 로 취급하여 Q 의 값을 추려낸다.\n",
    "    \n",
    "    # target Q 계산\n",
    "    max_Q = q_tar.Q(s2_buf).max(1)[0].unsqueeze(1) # 차원 줄이거나 늘리기. view 함수도 차원변환함\n",
    "    Q_targ = r_buf + GAMMA * max_Q\n",
    "    \n",
    "    # double DQN 업데이트\n",
    "    #a = q_net.Q(s2_buf).max(1)[0].unsqueeze(1)\n",
    "    #double_q = q_tar.Q(s2_buf).gather(1, a_buf)\n",
    "    #Q_targ = r_buf + GAMMA * double_q\n",
    "    \n",
    "    # loss\n",
    "    # mse 대신 huber loss 사용 - 덜 민감해서 급격한 변화 방지\n",
    "    # It is less sensitive to outliers than the MSELoss and in some cases prevents exploding gradients \n",
    "    loss = F.smooth_l1_loss(Q, Q_targ)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 13.0\n",
      "2 31.0\n",
      "3 19.0\n",
      "4 16.0\n",
      "5 65.0\n",
      "6 17.0\n",
      "7 11.0\n",
      "8 28.0\n",
      "9 12.0\n",
      "10 27.0\n",
      "11 27.0\n",
      "12 18.0\n",
      "13 29.0\n",
      "14 20.0\n",
      "15 25.0\n",
      "16 28.0\n",
      "17 9.0\n",
      "18 15.0\n",
      "19 18.0\n",
      "20 31.0\n",
      "21 11.0\n",
      "22 28.0\n",
      "23 26.0\n",
      "24 10.0\n",
      "25 23.0\n",
      "26 24.0\n",
      "27 25.0\n",
      "28 19.0\n",
      "29 12.0\n",
      "30 12.0\n",
      "31 12.0\n",
      "32 8.0\n",
      "33 24.0\n",
      "34 10.0\n",
      "35 11.0\n",
      "36 13.0\n",
      "37 38.0\n",
      "38 14.0\n",
      "39 49.0\n",
      "40 12.0\n",
      "41 10.0\n",
      "42 18.0\n",
      "43 26.0\n",
      "44 11.0\n",
      "45 11.0\n",
      "46 20.0\n",
      "47 12.0\n",
      "48 18.0\n",
      "49 19.0\n",
      "50 14.0\n",
      "51 38.0\n",
      "52 18.0\n",
      "53 9.0\n",
      "54 12.0\n",
      "55 14.0\n",
      "56 18.0\n",
      "57 14.0\n",
      "58 35.0\n",
      "59 9.0\n",
      "60 17.0\n",
      "61 11.0\n",
      "62 10.0\n",
      "63 12.0\n",
      "64 14.0\n",
      "65 14.0\n",
      "66 32.0\n",
      "67 12.0\n",
      "68 14.0\n",
      "69 20.0\n",
      "70 9.0\n",
      "71 13.0\n",
      "72 12.0\n",
      "73 10.0\n",
      "74 10.0\n",
      "75 15.0\n",
      "76 18.0\n",
      "77 19.0\n",
      "78 11.0\n",
      "79 26.0\n",
      "80 9.0\n",
      "81 15.0\n",
      "82 11.0\n",
      "83 11.0\n",
      "84 19.0\n",
      "85 19.0\n",
      "86 12.0\n",
      "87 24.0\n",
      "88 18.0\n",
      "89 17.0\n",
      "90 15.0\n",
      "91 10.0\n",
      "92 13.0\n",
      "93 11.0\n",
      "94 12.0\n",
      "95 18.0\n",
      "96 16.0\n",
      "97 10.0\n",
      "98 11.0\n",
      "99 26.0\n",
      "100 15.0\n",
      "101 16.0\n",
      "102 17.0\n",
      "103 12.0\n",
      "104 10.0\n",
      "105 16.0\n",
      "106 16.0\n",
      "107 10.0\n",
      "108 9.0\n",
      "109 13.0\n",
      "110 10.0\n",
      "111 21.0\n",
      "112 8.0\n",
      "113 11.0\n",
      "114 11.0\n",
      "115 14.0\n",
      "116 17.0\n",
      "117 11.0\n",
      "118 10.0\n",
      "119 9.0\n",
      "120 16.0\n",
      "121 12.0\n",
      "122 12.0\n",
      "123 9.0\n",
      "124 11.0\n",
      "125 26.0\n",
      "126 11.0\n",
      "127 9.0\n",
      "128 18.0\n",
      "129 9.0\n",
      "130 17.0\n",
      "131 10.0\n",
      "132 16.0\n",
      "133 12.0\n",
      "134 9.0\n",
      "135 10.0\n",
      "136 9.0\n",
      "137 9.0\n",
      "138 19.0\n",
      "139 12.0\n",
      "140 8.0\n",
      "141 13.0\n",
      "142 14.0\n",
      "143 14.0\n",
      "144 11.0\n",
      "145 10.0\n",
      "146 17.0\n",
      "147 16.0\n",
      "148 8.0\n",
      "149 8.0\n",
      "150 10.0\n",
      "151 12.0\n",
      "152 11.0\n",
      "153 10.0\n",
      "154 31.0\n",
      "155 13.0\n",
      "156 9.0\n",
      "157 9.0\n",
      "158 9.0\n",
      "159 8.0\n",
      "160 11.0\n",
      "161 18.0\n",
      "162 10.0\n",
      "163 11.0\n",
      "164 10.0\n",
      "165 9.0\n",
      "166 10.0\n",
      "167 12.0\n",
      "168 12.0\n",
      "169 8.0\n",
      "170 12.0\n",
      "171 10.0\n",
      "172 15.0\n",
      "173 11.0\n",
      "174 23.0\n",
      "175 13.0\n",
      "176 9.0\n",
      "177 11.0\n",
      "178 12.0\n",
      "179 11.0\n",
      "180 12.0\n",
      "181 17.0\n",
      "182 13.0\n",
      "183 11.0\n",
      "184 13.0\n",
      "185 10.0\n",
      "186 9.0\n",
      "187 11.0\n",
      "188 11.0\n",
      "189 11.0\n",
      "190 11.0\n",
      "191 10.0\n",
      "192 18.0\n",
      "193 12.0\n",
      "194 13.0\n",
      "195 10.0\n",
      "196 12.0\n",
      "197 12.0\n",
      "198 15.0\n",
      "199 10.0\n",
      "200 13.0\n",
      "201 11.0\n",
      "202 11.0\n",
      "203 13.0\n",
      "204 12.0\n",
      "205 10.0\n",
      "206 16.0\n",
      "207 9.0\n",
      "208 11.0\n",
      "209 9.0\n",
      "210 9.0\n",
      "211 10.0\n",
      "212 11.0\n",
      "213 13.0\n",
      "214 11.0\n",
      "215 9.0\n",
      "216 23.0\n",
      "217 10.0\n",
      "218 13.0\n",
      "219 13.0\n",
      "220 10.0\n",
      "221 13.0\n",
      "222 10.0\n",
      "223 12.0\n",
      "224 11.0\n",
      "225 10.0\n",
      "226 15.0\n",
      "227 10.0\n",
      "228 16.0\n",
      "229 8.0\n",
      "230 12.0\n",
      "231 9.0\n",
      "232 9.0\n",
      "233 11.0\n",
      "234 13.0\n",
      "235 11.0\n",
      "236 10.0\n",
      "237 12.0\n",
      "238 10.0\n",
      "239 19.0\n",
      "240 10.0\n",
      "241 10.0\n",
      "242 9.0\n",
      "243 14.0\n",
      "244 10.0\n",
      "245 10.0\n",
      "246 10.0\n",
      "247 10.0\n",
      "248 19.0\n",
      "249 12.0\n",
      "250 15.0\n",
      "251 12.0\n",
      "252 9.0\n",
      "253 10.0\n",
      "254 11.0\n",
      "255 12.0\n",
      "256 10.0\n",
      "257 8.0\n",
      "258 15.0\n",
      "259 9.0\n",
      "260 9.0\n",
      "261 8.0\n",
      "262 12.0\n",
      "263 9.0\n",
      "264 9.0\n",
      "265 9.0\n",
      "266 10.0\n",
      "267 10.0\n",
      "268 10.0\n",
      "269 10.0\n",
      "270 10.0\n",
      "271 12.0\n",
      "272 10.0\n",
      "273 10.0\n",
      "274 9.0\n",
      "275 9.0\n",
      "276 15.0\n",
      "277 11.0\n",
      "278 12.0\n",
      "279 10.0\n",
      "280 8.0\n",
      "281 12.0\n",
      "282 12.0\n",
      "283 9.0\n",
      "284 9.0\n",
      "285 12.0\n",
      "286 10.0\n",
      "287 9.0\n",
      "288 13.0\n",
      "289 9.0\n",
      "290 12.0\n",
      "291 11.0\n",
      "292 8.0\n",
      "293 11.0\n",
      "294 8.0\n",
      "295 10.0\n",
      "296 14.0\n",
      "297 12.0\n",
      "298 12.0\n",
      "299 10.0\n",
      "300 9.0\n",
      "301 9.0\n",
      "302 9.0\n",
      "303 9.0\n",
      "304 13.0\n",
      "305 9.0\n",
      "306 9.0\n",
      "307 11.0\n",
      "308 8.0\n",
      "309 19.0\n",
      "310 15.0\n",
      "311 10.0\n",
      "312 9.0\n",
      "313 10.0\n",
      "314 9.0\n",
      "315 14.0\n",
      "316 11.0\n",
      "317 10.0\n",
      "318 10.0\n",
      "319 8.0\n",
      "320 12.0\n",
      "321 12.0\n",
      "322 11.0\n",
      "323 12.0\n",
      "324 12.0\n",
      "325 13.0\n",
      "326 10.0\n",
      "327 10.0\n",
      "328 12.0\n",
      "329 11.0\n",
      "330 13.0\n",
      "331 9.0\n",
      "332 9.0\n",
      "333 10.0\n",
      "334 11.0\n",
      "335 11.0\n",
      "336 9.0\n",
      "337 12.0\n",
      "338 12.0\n",
      "339 14.0\n",
      "340 9.0\n",
      "341 11.0\n",
      "342 9.0\n",
      "343 14.0\n",
      "344 10.0\n",
      "345 10.0\n",
      "346 10.0\n",
      "347 10.0\n",
      "348 14.0\n",
      "349 10.0\n",
      "350 8.0\n",
      "351 12.0\n",
      "352 9.0\n",
      "353 11.0\n",
      "354 10.0\n",
      "355 13.0\n",
      "356 11.0\n",
      "357 12.0\n",
      "358 8.0\n",
      "359 9.0\n",
      "360 9.0\n",
      "361 10.0\n",
      "362 12.0\n",
      "363 12.0\n",
      "364 9.0\n",
      "365 10.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-9c4eb412bb81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQ_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m# step 진행\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "buffer = collections.deque(maxlen = 50000)\n",
    "ep = 1\n",
    "\n",
    "# network 생성\n",
    "q_net = DQN_Net()\n",
    "q_targ = DQN_Net()\n",
    "\n",
    "# target net 에 train net\n",
    "q_targ.load_state_dict(q_net.state_dict())\n",
    "\n",
    "# env 초기화\n",
    "state = env.reset()\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(q_net.parameters(), ALPHA)\n",
    "\n",
    "while(ep < EPISODE):\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    #EPSILON = max(0.01, 0.08 - 0.01*(ep/200))\n",
    "    \n",
    "    while(not done):    \n",
    "        # Q value 뽑기\n",
    "        Q_value = q_net.Q(torch.from_numpy(state).float())\n",
    "\n",
    "        # action 선택\n",
    "        if(random.random() < EPSILON):\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = Q_value.argmax().item()\n",
    "\n",
    "        # step 진행\n",
    "        state_next, reward, done, _ = env.step(action)\n",
    "        \n",
    "        # reward 합산\n",
    "        total_reward += reward\n",
    "        \n",
    "        # buffer 에 data stack\n",
    "        buffer.append((state, action, reward, state_next, done))\n",
    "        \n",
    "        # state 갱신\n",
    "        state = state_next\n",
    "        \n",
    "        # 학습\n",
    "        if(len(buffer) > 2000):\n",
    "            train(q_net, q_targ, optimizer)\n",
    "        \n",
    "        if(done):\n",
    "            \n",
    "            # periodical Update target net\n",
    "            if ep % Q_TARG_PERIOD == 0:\n",
    "                q_targ.load_state_dict(q_net.state_dict())\n",
    "                \n",
    "            print(ep, total_reward)\n",
    "            ep += 1\n",
    "            EPSILON = 1 / ((ep / 100) + 1)\n",
    "            state = env.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
