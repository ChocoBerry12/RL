{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPO\n",
    "---\n",
    "## torch 신경망 주의할 것\n",
    "* 업데이트 할 파라미터 정확히 지정하기 - detach 로 학습할 파라미터 확실하게 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "import gym\n",
    "import random\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PPO, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 32)\n",
    "        self.fc_pi = nn.Linear(32, 2)\n",
    "        self.fc_v = nn.Linear(32,1)\n",
    "    \n",
    "    def pi(self, x):\n",
    "        x = self.fc1(x)\n",
    "        prob = torch.softmax(self.fc_pi(x), dim = 0)\n",
    "        return prob\n",
    "    \n",
    "    def v(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc_v(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_factory(memory):\n",
    "    s_, a_, r_, s2_, d_, prob_ = [], [], [], [], [], []\n",
    "    for s, a, r, s2, d, p in memory:\n",
    "        s_.append(s)\n",
    "        a_.append([a])\n",
    "        r_.append([r])\n",
    "        s2_.append(s2)\n",
    "        d_.append([d])\n",
    "        prob_.append(p)\n",
    "        \n",
    "    s_ = torch.tensor(s_, dtype=torch.float)\n",
    "    a_ = torch.tensor(a_)\n",
    "    r_ = torch.tensor(r_)\n",
    "    s2_ = torch.tensor(s2_, dtype=torch.float)\n",
    "    d_ = torch.tensor(d_, dtype=torch.float)\n",
    "    prob_ = torch.tensor(prob_, dtype=torch.float)\n",
    "    \n",
    "    return s_, a_, r_, s2_, d_, prob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack(memory, item):\n",
    "    memory.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(memory, net):\n",
    "    s, a, r, s2, d, prob = batch_factory(memory)\n",
    "    \n",
    "    target = r + gamma * net.v(s2)\n",
    "    advantage = net.v(s) - target\n",
    "    \n",
    "    advantage_lst = []\n",
    "    advantage = 0.0\n",
    "    for delta_t in delta[::-1]:\n",
    "        advantage = gamma * lmbda * advantage + delta_t[0]\n",
    "        advantage_lst.append([advantage])\n",
    "    advantage_lst.reverse()\n",
    "    advantage = torch.tensor(advantage_lst, dtype=torch.float)\n",
    "\n",
    "    pi = net.pi(s)\n",
    "    pi_a = pi.gather(1, a)\n",
    "    ratio = pi_a / prob\n",
    "    \n",
    "    surr1 = ratio * advantage\n",
    "    surr2 = torch.clamp(ratio, 1 - e, 1 + e) * advantage\n",
    "    loss = -torch.min(surr1, surr2) + F.mse_loss(net.v(s), target.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train() missing 1 required positional argument: 'net'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ba3b01b2c8d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: train() missing 1 required positional argument: 'net'"
     ]
    }
   ],
   "source": [
    "net = PPO()\n",
    "ep = 1\n",
    "total_ep = 100\n",
    "buffer = collections.deque()\n",
    "\n",
    "while(ep < total_ep):\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    \n",
    "    while(not done):\n",
    "        prob = net.pi(torch.from_numpy(state).float())\n",
    "        action = Categorical(prob).sample().item()\n",
    "        state_next, reward, done, _ = env.step(action)\n",
    "        stack(buffer, (state, action, reward, state_next, done, prob))\n",
    "        if(done):\n",
    "            train(buffer, net)\n",
    "            ep += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
