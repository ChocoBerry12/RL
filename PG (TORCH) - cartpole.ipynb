{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla PG\n",
    "---\n",
    "* Monte-Carlo 방식 업데이트이므로 variance 가 높다\n",
    "---\n",
    "* torch 의 tensor 는 numpy array 와 유사하지만 GPU 에서 돌아갈 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "from torch.autograd import variable\n",
    "import numpy as np\n",
    "import gym\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODE = 1000\n",
    "EPSILON = 1\n",
    "RATE = .001\n",
    "GAMMA = .95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        self.data = []\n",
    "        self.fc1 = nn.Linear(4, 64)\n",
    "        self.outlayer = nn.Linear(64, 2)\n",
    "        self.optimizer = optim.Adam(self.parameters(), RATE)\n",
    "        \n",
    "    def pi(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.outlayer(x), dim=0)\n",
    "        return x\n",
    "    \n",
    "    def train(self):\n",
    "        discounted = 0\n",
    "        for r, log_p in self.data[::-1]:\n",
    "            discounted = r + GAMMA * discounted\n",
    "            # loss 정의\n",
    "            loss = - log_p * discounted\n",
    "            # 그래디언트 계산\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        self.data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.0\n",
      "21.0\n",
      "12.0\n",
      "14.0\n",
      "10.0\n",
      "8.0\n",
      "12.0\n",
      "19.0\n",
      "30.0\n",
      "21.0\n",
      "18.0\n",
      "62.0\n",
      "39.0\n",
      "27.0\n",
      "19.0\n",
      "23.0\n",
      "24.0\n",
      "16.0\n",
      "12.0\n",
      "17.0\n",
      "15.0\n",
      "20.0\n",
      "9.0\n",
      "41.0\n",
      "19.0\n",
      "18.0\n",
      "24.0\n",
      "10.0\n",
      "57.0\n",
      "11.0\n",
      "26.0\n",
      "44.0\n",
      "31.0\n",
      "16.0\n",
      "9.0\n",
      "26.0\n",
      "38.0\n",
      "19.0\n",
      "18.0\n",
      "19.0\n",
      "18.0\n",
      "27.0\n",
      "32.0\n",
      "25.0\n",
      "37.0\n",
      "23.0\n",
      "15.0\n",
      "39.0\n",
      "40.0\n",
      "20.0\n",
      "21.0\n",
      "20.0\n",
      "26.0\n",
      "33.0\n",
      "36.0\n",
      "45.0\n",
      "30.0\n",
      "18.0\n",
      "43.0\n",
      "13.0\n",
      "49.0\n",
      "23.0\n",
      "43.0\n",
      "26.0\n",
      "27.0\n",
      "25.0\n",
      "20.0\n",
      "28.0\n",
      "15.0\n",
      "9.0\n",
      "9.0\n",
      "25.0\n",
      "88.0\n",
      "19.0\n",
      "39.0\n",
      "51.0\n",
      "24.0\n",
      "49.0\n",
      "32.0\n",
      "20.0\n",
      "34.0\n",
      "21.0\n",
      "30.0\n",
      "66.0\n",
      "17.0\n",
      "40.0\n",
      "11.0\n",
      "23.0\n",
      "9.0\n",
      "28.0\n",
      "49.0\n",
      "40.0\n",
      "46.0\n",
      "26.0\n",
      "35.0\n",
      "20.0\n",
      "14.0\n",
      "32.0\n",
      "23.0\n",
      "31.0\n",
      "27.0\n",
      "72.0\n",
      "29.0\n",
      "99.0\n",
      "78.0\n",
      "40.0\n",
      "108.0\n",
      "88.0\n",
      "43.0\n",
      "57.0\n",
      "46.0\n",
      "126.0\n",
      "157.0\n",
      "70.0\n",
      "160.0\n",
      "132.0\n",
      "81.0\n",
      "56.0\n",
      "27.0\n",
      "90.0\n",
      "204.0\n",
      "106.0\n",
      "145.0\n",
      "151.0\n",
      "34.0\n",
      "103.0\n",
      "447.0\n",
      "146.0\n",
      "96.0\n",
      "156.0\n",
      "79.0\n",
      "49.0\n",
      "104.0\n",
      "75.0\n",
      "240.0\n",
      "551.0\n",
      "135.0\n",
      "112.0\n",
      "315.0\n",
      "676.0\n",
      "75.0\n",
      "1238.0\n",
      "137.0\n",
      "160.0\n",
      "521.0\n",
      "440.0\n",
      "404.0\n",
      "121.0\n",
      "593.0\n",
      "141.0\n",
      "217.0\n",
      "388.0\n",
      "300.0\n",
      "605.0\n",
      "570.0\n",
      "105.0\n",
      "133.0\n",
      "307.0\n",
      "101.0\n",
      "491.0\n",
      "127.0\n",
      "569.0\n",
      "294.0\n",
      "594.0\n",
      "158.0\n",
      "164.0\n",
      "640.0\n",
      "98.0\n",
      "302.0\n",
      "2000.0\n",
      "480.0\n",
      "447.0\n",
      "1796.0\n",
      "216.0\n",
      "241.0\n",
      "1179.0\n",
      "272.0\n",
      "186.0\n",
      "273.0\n",
      "276.0\n",
      "264.0\n",
      "203.0\n",
      "208.0\n",
      "398.0\n",
      "237.0\n",
      "306.0\n",
      "267.0\n",
      "275.0\n",
      "238.0\n",
      "328.0\n",
      "265.0\n",
      "398.0\n",
      "129.0\n",
      "199.0\n",
      "169.0\n",
      "194.0\n",
      "289.0\n",
      "192.0\n",
      "391.0\n",
      "238.0\n",
      "260.0\n",
      "198.0\n",
      "457.0\n",
      "198.0\n",
      "218.0\n",
      "379.0\n",
      "329.0\n",
      "193.0\n",
      "231.0\n",
      "209.0\n",
      "175.0\n",
      "223.0\n",
      "183.0\n",
      "290.0\n",
      "224.0\n",
      "319.0\n",
      "254.0\n",
      "207.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-736fab4c651f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[1;31m# 학습\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-3932c41f7122>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[1;31m# 그래디언트 계산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \"\"\"\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "ep = 1\n",
    "net = Policy()\n",
    "\n",
    "while(ep < EPISODE):\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while(not done):\n",
    "        #env.render()\n",
    "\n",
    "        # policy run\n",
    "        action_prob = net.pi(torch.from_numpy(state).float())\n",
    "        m = Categorical(action_prob)\n",
    "        a = m.sample()\n",
    "\n",
    "        # action 선택\n",
    "        if(EPSILON < random.randrange(0,1)):\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = a.item()\n",
    "\n",
    "        # step\n",
    "        state_next, reward, done, _ = env.step(action)\n",
    "\n",
    "        # reward 추가\n",
    "        total_reward += reward\n",
    "        \n",
    "        if(done):\n",
    "            reward = -100\n",
    "\n",
    "        # data 추가\n",
    "        net.data.append((reward, torch.log(action_prob[a])))\n",
    "\n",
    "        # state 갱신\n",
    "        state = state_next\n",
    "\n",
    "        # end episode\n",
    "        if(done):\n",
    "            print(total_reward)\n",
    "            total_reward = 0\n",
    "            ep += 1\n",
    "            \n",
    "            # env 초기화\n",
    "            state = env.reset()\n",
    "            EPSILON = 1 / (ep / 100 + 1)\n",
    "            \n",
    "            # 학습\n",
    "            net.train()\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
