{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmic - text manipulation\n",
    "---\n",
    "> 텍스트 알고리즘 학습. 복사, 뒤집기, 등 간단한 일을 하게 학습함. agent 가 문자열을 제대로 다 작성되거나 하나라도 틀리거나 시간이 너무 오래 지나면 종료한다. 처음엔 주어지는 input string 은 짧지만 episode 가 커질수록 문자열도 길어진다.\n",
    "\n",
    "* state : read head 의 위치\n",
    "* actoin : 2(좌우) x 2(write or not) x 5(what to write)\n",
    "* reward : 성공 시 + 1, 오류 시 -0.5, 시간초과 시 -1\n",
    "\n",
    "% openAi Gym 주의 - episode 끝나고 state 업데이트 해주기\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "환경 생성\n",
    "'''\n",
    "env = gym.make('Copy-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuple(Discrete(2), Discrete(2), Discrete(5))\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space)\n",
    "print(env.observation_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = np.zeros([20, env.observation_space.n])\n",
    "gamma = .95\n",
    "epsilon = 1\n",
    "alpha = .1\n",
    "episode_total = 2000\n",
    "episode = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_action(action):\n",
    "    return [int(action/10), int((action/5) % 2), action % 5]\n",
    "\n",
    "def encode_action(action):\n",
    "    return action[0]*10 + action[1]*5 + action[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "step = 0\n",
    "reward_total = 0\n",
    "\n",
    "while(episode < episode_total):\n",
    "    step += 1\n",
    "    if(random.random() < epsilon):\n",
    "        action = env.action_space.sample()\n",
    "    else:\n",
    "        action = np.argmax(q_table[ : , state])\n",
    "        action = decode_action(action)\n",
    "    \n",
    "    state_next, reward, done, _ = env.step(action)\n",
    "    reward -= .5\n",
    "    reward_total += reward\n",
    "    action = encode_action(action)\n",
    "    \n",
    "    q_table[action, state] += alpha * (reward + np.max(gamma * q_table[ : , state_next]) - q_table[action, state])\n",
    "    state = state_next\n",
    "\n",
    "    if(done):\n",
    "        if(reward > 0):\n",
    "            if(epsilon < .1):\n",
    "                epsilon = .1\n",
    "            else:\n",
    "                epsilon = 1 / (1 + episode / 100)\n",
    "        episode += 1\n",
    "        state = env.reset() # 꼭 해주기. 중요\n",
    "        step = 0\n",
    "        #print(reward_total)\n",
    "        reward_total = 0\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.54661179 -0.46489457 -0.61591941 -0.52880045 -0.56840773 -0.74533029]\n",
      " [-0.56749593 -0.46386748 -0.42324346 -0.46989764 -0.38140557 -0.73779281]\n",
      " [-0.50468414 -0.5767562  -0.57632526 -0.43641531 -0.61283298 -0.74532157]\n",
      " [-0.54737332 -0.45170561 -0.53642309 -0.5008144  -0.50461826 -0.74525236]\n",
      " [-0.48921005 -0.52722067 -0.5038153  -0.39035242 -0.594993   -0.75848013]\n",
      " [ 0.1627189  -1.12285529 -0.97007823 -0.97079137 -0.76549421 -0.98002622]\n",
      " [-0.71379974  0.27116988 -0.52975732 -1.10448376 -0.98018781 -0.75626181]\n",
      " [-0.9956953  -0.76707688 -0.01683418 -0.94039167 -0.88133887 -0.96362635]\n",
      " [-0.68283179 -0.95512881 -1.06456391  0.00211023 -0.9756859  -0.97731365]\n",
      " [-0.94111413 -0.87157309 -0.84303162 -0.85647861 -0.01475626 -1.06392201]\n",
      " [-0.09840329 -0.12613058 -0.15748441 -0.18673757 -0.14779175 -0.2954341 ]\n",
      " [-0.15850104 -0.09464548 -0.13941369 -0.16251746 -0.16058574 -0.40190317]\n",
      " [-0.19754563 -0.12389672 -0.13357666 -0.16494898 -0.08356571 -0.43164803]\n",
      " [-0.14597337 -0.11919677 -0.13184849 -0.16335774 -0.10024472 -0.26073189]\n",
      " [-0.07241859 -0.09901333 -0.08534298 -0.14092571 -0.09849028 -0.29020057]\n",
      " [ 0.42136045 -0.41238418 -0.54220188 -0.32878764 -0.56151031 -0.39476402]\n",
      " [-0.31701061  0.66533514 -0.60589261 -0.56539892 -0.42900337 -0.71288578]\n",
      " [-0.2703043  -0.49531501  0.47340435 -0.64923306 -0.41055822 -0.19494988]\n",
      " [-0.56048454 -0.61121014 -0.64868192  0.61186771 -0.49923395 -0.51263671]\n",
      " [-0.51579022 -0.48922521 -0.37721477 -0.60443115  0.5562934  -0.65527265]]\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "Total length of input instance: 31, step: 1\n",
      "===========================================\n",
      "Observation Tape    :   E\u001b[42mC\u001b[0mABADBCABBDCDACCACDABABCECABBE  \n",
      "Output Tape         :   \u001b[42mE\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   1.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: E)\n",
      "Total length of input instance: 31, step: 2\n",
      "===========================================\n",
      "Observation Tape    :   EC\u001b[42mA\u001b[0mBADBCABBDCDACCACDABABCECABBE  \n",
      "Output Tape         :   E\u001b[42mC\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   2.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: C)\n",
      "Total length of input instance: 31, step: 3\n",
      "===========================================\n",
      "Observation Tape    :   ECA\u001b[42mB\u001b[0mADBCABBDCDACCACDABABCECABBE  \n",
      "Output Tape         :   EC\u001b[42mA\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   3.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: A)\n",
      "Total length of input instance: 31, step: 4\n",
      "===========================================\n",
      "Observation Tape    :   ECAB\u001b[42mA\u001b[0mDBCABBDCDACCACDABABCECABBE  \n",
      "Output Tape         :   ECA\u001b[42mB\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   4.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: B)\n",
      "Total length of input instance: 31, step: 5\n",
      "===========================================\n",
      "Observation Tape    :   ECABA\u001b[42mD\u001b[0mBCABBDCDACCACDABABCECABBE  \n",
      "Output Tape         :   ECAB\u001b[42mA\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   5.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: A)\n",
      "Total length of input instance: 31, step: 6\n",
      "===========================================\n",
      "Observation Tape    :   ECABAD\u001b[42mB\u001b[0mCABBDCDACCACDABABCECABBE  \n",
      "Output Tape         :   ECABA\u001b[42mD\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   6.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: D)\n",
      "Total length of input instance: 31, step: 7\n",
      "===========================================\n",
      "Observation Tape    :   ECABADB\u001b[42mC\u001b[0mABBDCDACCACDABABCECABBE  \n",
      "Output Tape         :   ECABAD\u001b[42mB\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   7.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: B)\n",
      "Total length of input instance: 31, step: 8\n",
      "===========================================\n",
      "Observation Tape    :   ECABADBC\u001b[42mA\u001b[0mBBDCDACCACDABABCECABBE  \n",
      "Output Tape         :   ECABADB\u001b[42mC\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   8.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: C)\n",
      "Total length of input instance: 31, step: 9\n",
      "===========================================\n",
      "Observation Tape    :   ECABADBCA\u001b[42mB\u001b[0mBDCDACCACDABABCECABBE  \n",
      "Output Tape         :   ECABADBC\u001b[42mA\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   9.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: A)\n",
      "Total length of input instance: 31, step: 10\n",
      "============================================\n",
      "Observation Tape    :   ECABADBCAB\u001b[42mB\u001b[0mDCDACCACDABABCECABBE  \n",
      "Output Tape         :   ECABADBCA\u001b[42mB\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   10.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: B)\n",
      "Total length of input instance: 31, step: 11\n",
      "============================================\n",
      "Observation Tape    :   ECABADBCABB\u001b[42mD\u001b[0mCDACCACDABABCECABBE  \n",
      "Output Tape         :   ECABADBCAB\u001b[42mB\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   11.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: B)\n",
      "Total length of input instance: 31, step: 12\n",
      "============================================\n",
      "Observation Tape    :   ECABADBCABBD\u001b[42mC\u001b[0mDACCACDABABCECABBE  \n",
      "Output Tape         :   ECABADBCABB\u001b[42mD\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   12.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: D)\n",
      "Total length of input instance: 31, step: 13\n",
      "============================================\n",
      "Observation Tape    :   ECABADBCABBDC\u001b[42mD\u001b[0mACCACDABABCECABBE  \n",
      "Output Tape         :   ECABADBCABBD\u001b[42mC\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   13.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: C)\n",
      "Total length of input instance: 31, step: 14\n",
      "============================================\n",
      "Observation Tape    :   ECABADBCABBDCD\u001b[42mA\u001b[0mCCACDABABCECABBE  \n",
      "Output Tape         :   ECABADBCABBDC\u001b[42mD\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   14.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: D)\n",
      "Total length of input instance: 31, step: 15\n",
      "============================================\n",
      "Observation Tape    :   ECABADBCABBDCDA\u001b[42mC\u001b[0mCACDABABCECABBE  \n",
      "Output Tape         :   ECABADBCABBDCD\u001b[42mA\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   15.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: A)\n",
      "Total length of input instance: 31, step: 16\n",
      "============================================\n",
      "Observation Tape    :   ECABADBCABBDCDAC\u001b[42mC\u001b[0mACDABABCECABBE  \n",
      "Output Tape         :   ECABADBCABBDCDA\u001b[42mC\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   16.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: C)\n",
      "Total length of input instance: 31, step: 17\n",
      "============================================\n",
      "Observation Tape    :   ECABADBCABBDCDACC\u001b[42mA\u001b[0mCDABABCECABBE  \n",
      "Output Tape         :   ECABADBCABBDCDAC\u001b[42mC\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   17.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: C)\n",
      "Total length of input instance: 31, step: 18\n",
      "============================================\n",
      "Observation Tape    :   ECABADBCABBDCDACCA\u001b[42mC\u001b[0mDABABCECABBE  \n",
      "Output Tape         :   ECABADBCABBDCDACC\u001b[42mA\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   18.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: A)\n",
      "Total length of input instance: 31, step: 19\n",
      "============================================\n",
      "Observation Tape    :   ECABADBCABBDCDACCAC\u001b[42mD\u001b[0mABABCECABBE  \n",
      "Output Tape         :   ECABADBCABBDCDACCA\u001b[42mC\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   19.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: C)\n",
      "Total length of input instance: 31, step: 20\n",
      "============================================\n",
      "Observation Tape    :   ECABADBCABBDCDACCACD\u001b[42mA\u001b[0mBABCECABBE  \n",
      "Output Tape         :   ECABADBCABBDCDACCAC\u001b[42mD\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   20.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: D)\n",
      "Total length of input instance: 31, step: 21\n",
      "============================================\n",
      "Observation Tape    :   ECABADBCABBDCDACCACDA\u001b[42mB\u001b[0mABCECABBE  \n",
      "Output Tape         :   ECABADBCABBDCDACCACD\u001b[42mA\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   21.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: A)\n",
      "Total length of input instance: 31, step: 22\n",
      "============================================\n",
      "Observation Tape    :   ECABADBCABBDCDACCACDAB\u001b[42mA\u001b[0mBCECABBE  \n",
      "Output Tape         :   ECABADBCABBDCDACCACDA\u001b[42mB\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   22.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: B)\n",
      "Total length of input instance: 31, step: 23\n",
      "============================================\n",
      "Observation Tape    :   ECABADBCABBDCDACCACDABA\u001b[42mB\u001b[0mCECABBE  \n",
      "Output Tape         :   ECABADBCABBDCDACCACDAB\u001b[42mA\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   23.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: A)\n",
      "Total length of input instance: 31, step: 24\n",
      "============================================\n",
      "Observation Tape    :   ECABADBCABBDCDACCACDABAB\u001b[42mC\u001b[0mECABBE  \n",
      "Output Tape         :   ECABADBCABBDCDACCACDABA\u001b[42mB\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   24.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: B)\n",
      "Total length of input instance: 31, step: 25\n",
      "============================================\n",
      "Observation Tape    :   ECABADBCABBDCDACCACDABABC\u001b[42mE\u001b[0mCABBE  \n",
      "Output Tape         :   ECABADBCABBDCDACCACDABAB\u001b[42mC\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   25.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: C)\n",
      "Total length of input instance: 31, step: 26\n",
      "============================================\n",
      "Observation Tape    :   ECABADBCABBDCDACCACDABABCE\u001b[42mC\u001b[0mABBE  \n",
      "Output Tape         :   ECABADBCABBDCDACCACDABABC\u001b[42mE\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   26.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: E)\n",
      "Total length of input instance: 31, step: 27\n",
      "============================================\n",
      "Observation Tape    :   ECABADBCABBDCDACCACDABABCEC\u001b[42mA\u001b[0mBBE  \n",
      "Output Tape         :   ECABADBCABBDCDACCACDABABCE\u001b[42mC\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   27.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: C)\n",
      "Total length of input instance: 31, step: 28\n",
      "============================================\n",
      "Observation Tape    :   ECABADBCABBDCDACCACDABABCECA\u001b[42mB\u001b[0mBE  \n",
      "Output Tape         :   ECABADBCABBDCDACCACDABABCEC\u001b[42mA\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   28.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: A)\n",
      "Total length of input instance: 31, step: 29\n",
      "============================================\n",
      "Observation Tape    :   ECABADBCABBDCDACCACDABABCECAB\u001b[42mB\u001b[0mE  \n",
      "Output Tape         :   ECABADBCABBDCDACCACDABABCECA\u001b[42mB\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   29.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: B)\n",
      "Total length of input instance: 31, step: 30\n",
      "============================================\n",
      "Observation Tape    :   ECABADBCABBDCDACCACDABABCECABB\u001b[42mE\u001b[0m  \n",
      "Output Tape         :   ECABADBCABBDCDACCACDABABCECAB\u001b[42mB\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   30.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: B)\n",
      "Total length of input instance: 31, step: 31\n",
      "============================================\n",
      "Observation Tape    :   ECABADBCABBDCDACCACDABABCECABBE\u001b[42m \u001b[0m \n",
      "Output Tape         :   ECABADBCABBDCDACCACDABABCECABB\u001b[42mE\u001b[0m\n",
      "Targets             :   ECABADBCABBDCDACCACDABABCECABBE  \n",
      "\n",
      "Current reward      :   1.000\n",
      "Cumulative reward   :   31.000\n",
      "Action              :   Tuple(move over input: right,\n",
      "                              write to the output tape: True,\n",
      "                              prediction: E)\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "30.0\n",
      "32.0\n",
      "31.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "32.0\n",
      "31.0\n",
      "32.0\n",
      "30.0\n",
      "31.0\n",
      "31.0\n",
      "30.0\n",
      "32.0\n",
      "32.0\n",
      "31.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-626-f7abeaed41f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_table\u001b[0m\u001b[1;33m[\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0m_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecode_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(a, axis, out)\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m     \"\"\"\n\u001b[1;32m-> 1037\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(q_table)\n",
    "s = env.reset()\n",
    "reward_sum = 0\n",
    "ep = 0\n",
    "\n",
    "while(True):\n",
    "    a = np.argmax(q_table[ : , s])\n",
    "    _a = decode_action(a)\n",
    "    s,r,d,_ = env.step(_a)\n",
    "    if(ep == 100):\n",
    "        env.render()\n",
    "        \n",
    "    reward_sum += r\n",
    "    if(d):\n",
    "        ep += 1\n",
    "        s = env.reset() # 꼭 해주기. 중요\n",
    "        print(reward_sum)\n",
    "        reward_sum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 어느 짱깨가 만든 몬테카를로 알고리즘\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final policy: [15, 16, 17, 18, 19, 15]\n",
      "episodes trained: 4999\n",
      "total reward: 30.000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "\n",
    "env = gym.make('Copy-v0')\n",
    "\n",
    "# observation_space: Discrete(6)\n",
    "# action_space: (Discrete(2), Discrete(2), Discrete(5))\n",
    "\n",
    "# states: 0, 1, 2, 3, 4, 5\n",
    "\n",
    "# MARK: problem specific functions\n",
    "\n",
    "\n",
    "def action_to_index(action):\n",
    "    return action[0]*10+action[1]*5+action[2]\n",
    "\n",
    "\n",
    "def index_to_action(index):\n",
    "    action = [int(index/10), int((index/5) % 2), index % 5]\n",
    "    return tuple(action)\n",
    "\n",
    "\n",
    "# MARK: Monte Carlo ES method\n",
    "\n",
    "STATE_COUNT = 6\n",
    "ACTION_COUNT = 20\n",
    "\n",
    "\n",
    "def init_mces(state_count, action_count):\n",
    "    q = np.random.rand(state_count, action_count)\n",
    "    rets = np.zeros((state_count, action_count), dtype=np.double)\n",
    "    policy = [random.randint(0, action_count-1) for _ in range(state_count)]\n",
    "    return q, rets, policy\n",
    "\n",
    "\n",
    "def learning(env):\n",
    "    q, rets, policy = init_mces(STATE_COUNT, ACTION_COUNT)\n",
    "    gamma = 0.7\n",
    "    epsilon = 1\n",
    "    total_score = 0.0\n",
    "    i_episode = 0\n",
    "\n",
    "    for i_episode in range(5000):\n",
    "        total_reward = 0\n",
    "        observation = env.reset()\n",
    "        g = np.zeros((STATE_COUNT, ACTION_COUNT), dtype=np.double)\n",
    "        passed = np.zeros((STATE_COUNT, ACTION_COUNT), dtype=np.double)\n",
    "\n",
    "        for t in range(100):\n",
    "            raw_action = policy[observation]\n",
    "            # 1 - epsilon greedy\n",
    "            if random.random() < epsilon:\n",
    "                raw_action = action_to_index((random.randint(0, 1),\n",
    "                                              random.randint(0, 1),\n",
    "                                              random.randint(0, 4)))\n",
    "            if passed[observation, raw_action] == 0.0:\n",
    "                passed[observation, raw_action] = 1.0\n",
    "\n",
    "            action = index_to_action(raw_action)\n",
    "            #env.render()\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            reward -= 0.5  # IMPORTANT: punish useless (even dangerous) actions whose environment reward is 0.0\n",
    "            total_reward += reward\n",
    "\n",
    "            for i in range(STATE_COUNT):\n",
    "                for j in range(ACTION_COUNT):\n",
    "                    passed[i][j] *= gamma\n",
    "                    g[i][j] += reward * passed[i][j]\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # reduce exploration chance\n",
    "        if i_episode % 100 == 0:\n",
    "            epsilon *= 0.9\n",
    "\n",
    "        rets += g\n",
    "        q = rets / (i_episode+1)\n",
    "        policy = np.argmax(q, axis=1).tolist()\n",
    "\n",
    "        total_score += total_reward\n",
    "\n",
    "    return policy, i_episode\n",
    "\n",
    "\n",
    "def test_policy(env, policy):\n",
    "    total_reward = 0.0\n",
    "    obs = env.reset()\n",
    "    for t in range(1000):\n",
    "        action = index_to_action(policy[obs])\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        env.render()\n",
    "        if done:\n",
    "            break\n",
    "    print('total reward: %f'%total_reward)\n",
    "\n",
    "\n",
    "#env.monitor.start('Copyv0-experiment-0')\n",
    "policy, n_episode = learning(env)\n",
    "#env.monitor.close()\n",
    "\n",
    "print('final policy: '+str(policy))\n",
    "print('episodes trained: '+str(n_episode))\n",
    "test_policy(env, policy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
